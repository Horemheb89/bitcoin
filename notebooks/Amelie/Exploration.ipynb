{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mean = stats.mean(results)\n",
    "# std = round(stats.stdev(results),2)\n",
    "# min_s = min(results)\n",
    "# max_s = max(results)\n",
    "\n",
    "summary =  pd.DataFrame(np.array([[stats.mean(results), round(stats.stdev(results),2), min(results), max(results)]]),\n",
    "                   columns=['mean_score', 'std', 'score_min', 'score_max'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std</th>\n",
       "      <th>score_min</th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_score   std  score_min  score_max\n",
       "0         2.5  1.29        1.0        4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../raw_data/bitstampUSD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../raw_data/bitstampUSD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s', origin='unix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_2012 = df[df['Timestamp'].dt.year == 2012]['Open'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nan_2012).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_2012.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(np.arange(2011, 2021, 1))\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(df[df['Timestamp'].dt.year == 2015]['Open'].value_counts(dropna=False)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[0,'Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Open'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_na(X):\n",
    "    years = [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
    "    missing_values = pd.DataFrame()\n",
    "    for y in years:\n",
    "#         nan_Open = pd.DataFrame(X[X['Timestamp'].dt.year == y]['Open'].value_counts(dropna=False)).reset_index()\n",
    "#         nan_Close = pd.DataFrame(X[X['Timestamp'].dt.year == y]['Close'].value_counts(dropna=False)).reset_index()\n",
    "        missing_values['year'] = y\n",
    "        missing_values['total_Open'] = pd.DataFrame(X[X['Timestamp'].dt.year == y]['Open'].value_counts(dropna=False)).reset_index()['Open'].sum()\n",
    "        missing_values['Open_nan'] = pd.DataFrame(X[X['Timestamp'].dt.year == y]['Open'].value_counts(dropna=False)).reset_index().iloc[0,1]\n",
    "        missing_values['total_Close'] = pd.DataFrame(X[X['Timestamp'].dt.year == y]['Close'].value_counts(dropna=False)).reset_index()['Close'].sum()\n",
    "        missing_values['Close_nan'] = pd.DataFrame(X[X['Timestamp'].dt.year == y]['Close'].value_counts(dropna=False)).reset_index().iloc[0,1]\n",
    "        return missing_values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df[df['Timestamp'].dt.year == 2014]['Open'].value_counts(dropna=False)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df[df['Timestamp'].dt.year == 2015]['Open'].value_counts(dropna=False)).reset_index()['Open'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fonction nan exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthna(X):\n",
    "    months = list(np.arange(1,13,1))\n",
    "\n",
    "    open_nan = []\n",
    "    open_sum = []\n",
    "\n",
    "    for x in months:\n",
    "        open_sum.append(pd.DataFrame(X[X['Timestamp'].dt.month == x]['Open'].value_counts(dropna=False)).reset_index()['Open'].sum())\n",
    "        open_nan.append(pd.DataFrame(X[X['Timestamp'].dt.month == x]['Open'].value_counts(dropna=False)).reset_index().iloc[0,1])\n",
    "       \n",
    "    M = pd.Series(months)\n",
    "    ON = pd.Series(open_nan)\n",
    "    OS = pd.Series(open_sum)\n",
    "    \n",
    "    return pd.DataFrame((pd.concat([ON, OS], axis=1).set_index(M))).rename(columns={0:'Count NA Open', 1:'Total Open'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_year(data):\n",
    "    year_df = []\n",
    "    years = list(np.arange(2011, 2021, 1))\n",
    "    for year in years:\n",
    "        data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "        df = data[data['Timestamp'].dt.year == year]\n",
    "        year_df.append(df)\n",
    "    return year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df = dataframe_year(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df = dataframe_year(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_month(data):\n",
    "    \n",
    "    month_df = []\n",
    "    year_df = dataframe_year(data)\n",
    "\n",
    "    for i in range(0, 9):\n",
    "        month = monthna(year_df[i])\n",
    "        month['percent NA OP'] = round((month['Count NA Open']/month['Total Open'])*100, 2)\n",
    "        month = month.drop(columns=['Count NA Open', 'Total Open', 'Count NA Close', 'Totaal Close'])\n",
    "        month_df.append(month_df)\n",
    "\n",
    "    return month_df[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe_month(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [df_month_14, df_month_15, df_month_16, df_month_17, df_month_18, df_month_19, df_month_20]\n",
    "# df_final = pd.concat([df_month_14, df_month_15, df_month_16, df_month_17, df_month_18, df_month_19, df_month_20], axis= 1)\n",
    "# df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df[df['Timestamp'].dt.year == 2011]['Open'].value_counts(dropna=False)).reset_index()['Open'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df[df['Timestamp'].dt.year == 2012]['Open'].value_counts(dropna=False)).reset_index()['Open'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df[df['Timestamp'].dt.year == 2013]['Open'].value_counts(dropna=False)).reset_index()['Open'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df[df['Timestamp'].dt.year == 2015]['Open'].value_counts(dropna=False)).reset_index()['Open'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countna(X):\n",
    "    years = list(np.arange(2011,2021,1))\n",
    "    open_nan = []\n",
    "    open_sum = []\n",
    "    close_nan = []\n",
    "    close_sum = []\n",
    "    missing_values = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for x in years:\n",
    "        open_sum.append(pd.DataFrame(X[X['Timestamp'].dt.year == x]['Open'].value_counts(dropna=False)).reset_index()['Open'].sum())\n",
    "        open_nan.append(pd.DataFrame(X[X['Timestamp'].dt.year == x]['Open'].value_counts(dropna=False)).reset_index().iloc[0,1])\n",
    "        close_sum.append(pd.DataFrame(X[X['Timestamp'].dt.year == x]['Close'].value_counts(dropna=False)).reset_index()['Close'].sum())\n",
    "        close_nan.append(pd.DataFrame(X[X['Timestamp'].dt.year == x]['Close'].value_counts(dropna=False)).reset_index().iloc[0,1])\n",
    "    Y = pd.Series(years)\n",
    "    ON = pd.Series(open_nan)\n",
    "    OS = pd.Series(open_sum)\n",
    "    CN = pd.Series(close_nan)\n",
    "    CS =pd.Series(close_sum)\n",
    "    return pd.DataFrame((pd.concat([ON, OS, CN, CS], axis=1).set_index(Y))).rename(columns={0:'Count NA Open', 1:'Total Open', 2:'Count NA Close', 3:'Total Close'})\n",
    "#     missing_values['years'] = x\n",
    "#     missing_values['close'] = \n",
    "#     missing_values['nan_close'] =\n",
    "#     missing_values['open'] = \n",
    "#     missing_values['nan_open'] = open_nan\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_null = countna(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTTTTTTTT et calcul %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = df[df['Timestamp'].dt.year == 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014[df_2014['Timestamp'].dt.month == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthna(X):\n",
    "    months = list(np.arange(1,13,1))\n",
    "\n",
    "    open_nan = []\n",
    "    open_sum = []\n",
    "    close_nan = []\n",
    "    close_sum = []\n",
    "\n",
    "\n",
    "    for x in months:\n",
    "        open_sum.append(pd.DataFrame(X[X['Timestamp'].dt.month == x]['Open'].value_counts(dropna=False)).reset_index()['Open'].sum())\n",
    "        open_nan.append(pd.DataFrame(X[X['Timestamp'].dt.month == x]['Open'].value_counts(dropna=False)).reset_index().iloc[0,1])\n",
    "        close_sum.append(pd.DataFrame(X[X['Timestamp'].dt.month == x]['Close'].value_counts(dropna=False)).reset_index()['Close'].sum())\n",
    "        close_nan.append(pd.DataFrame(X[X['Timestamp'].dt.month == x]['Close'].value_counts(dropna=False)).reset_index().iloc[0,1])\n",
    "    M = pd.Series(months)\n",
    "    ON = pd.Series(open_nan)\n",
    "    OS = pd.Series(open_sum)\n",
    "    CN = pd.Series(close_nan)\n",
    "    CS = pd.Series(close_sum)\n",
    "    return pd.DataFrame((pd.concat([ON, OS, CN, CS], axis=1).set_index(M))).rename(columns={0:'Count NA Open', 1:'Total Open', 2:'Count NA Close', 3:'Total Close'})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = df[df['Timestamp'].dt.year == 2014]\n",
    "df_month_14 = monthna(df_2014)\n",
    "df_month_14['percent NA OP'] = round((df_month_14['Count NA Open']/df_month_14['Total Open'])*100, 2)\n",
    "df_month_14['percent NA CL'] = round((df_month_14['Count NA Close']/df_month_14['Total Close'])*100, 2)\n",
    "df_month_14 = df_month_14.drop(columns=['Count NA Open', 'Total Open', 'Count NA Close', 'Total Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def all_na(X):\n",
    "#     years = list(np.arange(2011,2021,1))\n",
    "#     df_years_list = []\n",
    "    \n",
    "#     for y in years:\n",
    "#         Y = X[X['Timestamp'].dt.year == y]\n",
    "#         df_years_list.append(monthna(Y))\n",
    "#         final_df_years = pd.concat(df_years_list)\n",
    "#     return final_df_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_na(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = df[df['Timestamp'].dt.year == 2015]\n",
    "df_month_15 = monthna(df_2015)\n",
    "df_month_15['percent NA OP'] = round((df_month_15['Count NA Open']/df_month_15['Total Open'])*100, 2)\n",
    "df_month_15['percent NA CL'] = round((df_month_15['Count NA Close']/df_month_15['Total Close'])*100, 2)\n",
    "df_month_15 = df_month_15.drop(columns=['Count NA Open', 'Total Open', 'Count NA Close', 'Total Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df[df['Timestamp'].dt.year == 2016]\n",
    "df_month_16 = monthna(df_2016)\n",
    "df_month_16['percent NA OP'] = round((df_month_16['Count NA Open']/df_month_16['Total Open'])*100, 2)\n",
    "df_month_16['percent NA CL'] = round((df_month_16['Count NA Close']/df_month_16['Total Close'])*100, 2)\n",
    "df_month_16 = df_month_16.drop(columns=['Count NA Open', 'Total Open', 'Count NA Close', 'Total Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df[df['Timestamp'].dt.year == 2017]\n",
    "df_month_17 = monthna(df_2017)\n",
    "df_month_17['percent NA OP'] = round((df_month_17['Count NA Open']/df_month_17['Total Open'])*100, 2)\n",
    "df_month_17['percent NA CL'] = round((df_month_17['Count NA Close']/df_month_17['Total Close'])*100, 2)\n",
    "df_month_17 = df_month_17.drop(columns=['Count NA Open', 'Total Open', 'Count NA Close', 'Total Close'])\n",
    "df_month_17 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = df[df['Timestamp'].dt.year == 2018]\n",
    "df_month_18 = monthna(df_2018)\n",
    "df_month_18['percent NA OP'] = round((df_month_18['Count NA Open']/df_month_18['Total Open'])*100, 2)\n",
    "df_month_18['percent NA CL'] = round((df_month_18['Count NA Close']/df_month_18['Total Close'])*100, 2)\n",
    "df_month_18 = df_month_18.drop(columns=['Count NA Open', 'Total Open', 'Count NA Close', 'Total Close'])\n",
    "df_month_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = df[df['Timestamp'].dt.year == 2019]\n",
    "df_month_19 = monthna(df_2019)\n",
    "df_month_19['percent NA OP'] = round((df_month_19['Count NA Open']/df_month_19['Total Open'])*100, 2)\n",
    "df_month_19['percent NA CL'] = round((df_month_19['Count NA Close']/df_month_19['Total Close'])*100, 2)\n",
    "df_month_19 = df_month_19.drop(columns=['Count NA Open', 'Total Open', 'Count NA Close', 'Total Close'])\n",
    "df_month_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020 = df[df['Timestamp'].dt.year == 2020]\n",
    "df_month_20 = monthna(df_2020)\n",
    "df_month_20['percent NA OP'] = round((df_month_20['Count NA Open']/df_month_20['Total Open'])*100, 2)\n",
    "df_month_20['percent NA CL'] = round((df_month_20['Count NA Close']/df_month_20['Total Close'])*100, 2)\n",
    "df_month_20 = df_month_20.drop(columns=['Count NA Open', 'Total Open', 'Count NA Close', 'Total Close'])\n",
    "df_month_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_month_14, df_month_15, df_month_16, df_month_17, df_month_18, df_month_19, df_month_20]\n",
    "df_final = pd.concat([df_month_14, df_month_15, df_month_16, df_month_17, df_month_18, df_month_19, df_month_20], axis= 1)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017[df_2017['Timestamp'].dt.month == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020[df_2020['Timestamp'].dt.month == 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4727776 - 2798176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2798176 + (1929600/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2991136.0 + (1929600/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2991136.0 + (1929600/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2798176\n",
    "a = 1929600/10\n",
    "index_list = []\n",
    "while x < 4727776:\n",
    "    index_list.append(x+a)\n",
    "    x = x + a\n",
    "print(index_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_df_i = []\n",
    "# for x in index_list:\n",
    "#     L = f\"{x} ':' {index_list[(index_list.index(x))+1]}\"\n",
    "#     list_df_i.append([L])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(f\"(2798176 : {round(index_list[0])})\")\n",
    "\n",
    "index_df = []\n",
    "for i in range(9):\n",
    "    index_df.append((f\"({round(index_list[i])}:{round(index_list[i+1])})\"))\n",
    "print(index_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[2798176:2991136]\n",
    "df_2 = df[2991137:3184096]\n",
    "df_3 = df[3184097:3377056]\n",
    "df_4 = df[3377057:3570016]\n",
    "df_5 = df[3570017:3762976]\n",
    "df_6 = df[3762977:3955936]\n",
    "df_7 = df[3955937:4148896]\n",
    "df_8 = df[4148897:4341856]\n",
    "df_9 = df[4341857:4534816]\n",
    "df_10 = df[4534817:4727776]\n",
    "df_11 = df[4527776:4727776]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4727776 - 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9, df_10, df_11]\n",
    "df_open = []\n",
    "for x in df_list:\n",
    "    x = x.drop(columns=['High', 'Low', 'Close', 'Volume_(BTC)', 'Volume_(Currency)', 'Weighted_Price'])\n",
    "    df_open.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_final = df_open[0]\n",
    "df_2_final = df_open[1]\n",
    "df_3_final = df_open[2]\n",
    "df_4_final = df_open[3]\n",
    "df_5_final = df_open[4]\n",
    "df_6_final = df_open[5]\n",
    "df_7_final = df_open[6]\n",
    "df_8_final = df_open[7]\n",
    "df_9_final = df_open[8]\n",
    "df_10_final = df_open[9]\n",
    "df_11_final = df_open[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10_train = df_10_final[0:189359]\n",
    "# df_10_test = df_10_final[189360:192958]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11_train = df_11_final[0:196399]\n",
    "df_11_test = df_11_final[196400:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, 61):\n",
    "#     df_10_train[f't - {i}'] = df_10_train['Open'].shift(i)\n",
    "# df_10_train.dropna(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 61):\n",
    "    df_11_train[f't - {i}'] = df_11_train['Open'].shift(i)\n",
    "df_11_train.dropna(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, 61):\n",
    "#     df_10_test[f't - {i}'] = df_10_test['Open'].shift(i)\n",
    "# df_10_test.dropna(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 61):\n",
    "    df_11_test[f't - {i}'] = df_11_test['Open'].shift(i)\n",
    "df_11_test.dropna(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X10_train = df_10_train.drop(columns=['Open'])\n",
    "# y10_train = df_10_train['Open']\n",
    "# X10_test = df_10_test.drop(columns=['Open'])\n",
    "# y10_test = df_10_test['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y10_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import r2_score\n",
    "# model = LinearRegression()\n",
    "# model = model.fit(X10_train, y10_train)\n",
    "\n",
    "# print('R2: ', r2_score(y10_test, model.predict(X10_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA\n",
    "upload data\n",
    "GCP\n",
    "upload data gcp\n",
    "\n",
    "clean : NaN\n",
    "\n",
    "PARAMS.gcp\n",
    "\n",
    "PARAMS.trainer\n",
    "\n",
    "TRAINER\n",
    "cree train test split avec hyperparametres\n",
    "fonction window train\n",
    "fonction window test\n",
    "fit\n",
    "params utilisé -> mlflow -> gcp\n",
    "\n",
    "Grid search  ? model ? \n",
    "\n",
    "fichier model\n",
    "\n",
    "trainer \n",
    "appelé fichier model\n",
    "fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def input_data():\n",
    "\n",
    "\n",
    "df_12 = df[4527776:4727776]\n",
    "\n",
    "df_list_12 = [df_12]\n",
    "df_open_12 = []\n",
    "\n",
    "for x in df_list_12:\n",
    "    x = x.drop(columns=['High', 'Low', 'Close', 'Volume_(BTC)', 'Volume_(Currency)', 'Weighted_Price'])\n",
    "    df_open_12.append(x)\n",
    "    \n",
    "\n",
    "df_12_final = df_open_12[0]\n",
    "\n",
    "df_12_final.fillna(method='backfill', inplace=True)\n",
    "df_12_final.isna().sum()\n",
    "\n",
    "for i in range(1, 61):\n",
    "    df_12_final[f't - {i}'] = df_12_final['Open'].shift(i)\n",
    "df_12_final.dropna(inplace=True) \n",
    "\n",
    "# X12 = df_12_final.drop(columns=['Open'])\n",
    "X12 = df_12_final.drop(columns=['Open', 'Timestamp'])\n",
    "y12 = df_12_final['Open']\n",
    "\n",
    "\n",
    "X12_train = X12[0:129600]\n",
    "y12_train = y12[0:129600]\n",
    "X12_test = X12[129601:199940]\n",
    "y12_test = y12[129601:199940]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(data, sample_size, shift_size, train_size):\n",
    "\n",
    "    data_size = data.shape[0]\n",
    "    sample = data.iloc[(data_size-sample_size):data_size]\n",
    "    sample_pp = sample[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='backfill')\n",
    "\n",
    "\n",
    "    for i in range(1, shift_size+1):\n",
    "        sample_pp[f't - {i}'] = sample_pp['Open'].shift(i)\n",
    "    sample_shifted = sample_pp.dropna() \n",
    "\n",
    "\n",
    "    X = sample_shifted.drop(columns=['Open'])\n",
    "    y = sample_shifted['Open']\n",
    "\n",
    "\n",
    "    X_train = X.iloc[0:train_size]\n",
    "    y_train = y.iloc[0:train_size]\n",
    "    X_test = X.iloc[(train_size+1):(sample_size-shift_size)]\n",
    "    y_test = y.iloc[(train_size+1):(sample_size-shift_size)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"Timestamp\")[\"2020-08-01\":\"2020-10-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(\n",
    "    {\"Open\": range(1, 21), \"Timestamp\": pd.date_range(\"2021-01-01\", periods=20, freq=\"D\")}\n",
    ")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input_data function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(data, sample_size, shift_size, train_size, h=1, w=0):\n",
    "    \n",
    "    data_size = data.shape[0]\n",
    "    sample = data.iloc[(data_size-sample_size-w):data_size-w]\n",
    "    sample_pp = sample[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='backfill')\n",
    "\n",
    "\n",
    "    for i in range(0, shift_size):\n",
    "        sample_pp[f't-{i}'] = sample_pp['Open'].shift(i)\n",
    "    sample_shifted = sample_pp.dropna() \n",
    "\n",
    "\n",
    "    X = sample_shifted.drop(columns=['Open'])\n",
    "    y = sample_shifted['Open'].shift(-h).rename(f\"t+{h}\")\n",
    "\n",
    "\n",
    "    X_train = X.iloc[0:train_size]\n",
    "    y_train = y.iloc[0:train_size] #[0+h:train_size+h]\n",
    "    \n",
    "    X_test = X.iloc[(train_size+h-1):(sample_size-shift_size)]\n",
    "    y_test = y.iloc[(train_size+h-1):(sample_size-shift_size)] #[(train_size+(h*2)+1):(sample_size-shift_size)] \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = input_data(test_df, 15, 3, 5, h=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input_data fucntion sample with dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(data, data_start, data_end, sample_size, w=0, shift_size, train_size, h=0):\n",
    "    \n",
    "    if data_start != None:\n",
    "        elif data_end != None:\n",
    "            sample = data[:]\n",
    "            \n",
    "    \n",
    "    data_size = data.shape[0]\n",
    "    sample = data.iloc[(data_size-sample_size-w):data_size-w]\n",
    "    sample_pp = sample[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='backfill')\n",
    "\n",
    "\n",
    "    for i in range(1, shift_size+1):\n",
    "        sample_pp[f't - {i}'] = sample_pp['Open'].shift(i)\n",
    "    sample_shifted = sample_pp.dropna() \n",
    "\n",
    "\n",
    "    X = sample_shifted.drop(columns=['Open'])\n",
    "    y = sample_shifted['Open']\n",
    "\n",
    "\n",
    "    X_train = X.iloc[0:train_size]\n",
    "    y_train = y.iloc[0+h:train_size+h]\n",
    "    \n",
    "    X_test = X.iloc[(train_size+h+1):(sample_size-shift_size)]\n",
    "    y_test = y.iloc[(train_size+(h*2)+1):(sample_size-shift_size)] \n",
    "    \n",
    " \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input_data function last version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data, shift_size, h=1, test=False):\n",
    "    \n",
    "    \n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data_pp = data_pp.dropna()\n",
    "    \n",
    "    for i in range(0, shift_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna() \n",
    "    \n",
    "    \n",
    "    data_shifted['diff_open'] = data_shifted['Open'].diff(h)\n",
    "    \n",
    "    X = data_shifted.drop(columns=['Open'])\n",
    "    y = data_shifted['diff_open'].rename(f\"t+{h}\").map(lambda x: 0 if x <= 0 else 1)\n",
    "    \n",
    "    return X, y \n",
    "\n",
    "\n",
    "def input_data(data_shifted, sample_size, shift_size, train_size, h=1, w=0):\n",
    "    \n",
    "    data_size = data_pp.shape[0]\n",
    "    sample = data.iloc[(data_size-sample_size-w):data_size-w]\n",
    "\n",
    "    X_train = X.iloc[0:train_size]\n",
    "    y_train = y.iloc[0:train_size] \n",
    "    \n",
    "    X_test = X.iloc[(train_size+h-1):(sample_size-shift_size)]\n",
    "    y_test = y.iloc[(train_size+h-1):(sample_size-shift_size)] \n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-function test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data_test(data, shift_size, h=3, test=False):\n",
    "    \n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    # data_pp['open_diff'] = data_pp['Open'].diff()\n",
    "    data_pp = data_pp.dropna()\n",
    "    \n",
    "    for i in range(0, shift_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna() \n",
    "    \n",
    "    \n",
    "    X = data_shifted.drop(columns=['Open'])\n",
    "    y = data_shifted['Open'].diff(h).rename(f\"t+{h}\")\n",
    "    \n",
    "    # y = data_shifted['Open'].shift(-h).rename(f\"t+{h}\")\n",
    "    \n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data_test2(data, shift_size, h=1, test=False):\n",
    "    \n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data_pp = data_pp.dropna()\n",
    "    \n",
    "    for i in range(0, shift_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna() \n",
    "    \n",
    "    \n",
    "    data_shifted['diff_open'] = data_shifted['Open'].diff(h)\n",
    "    X = data_shifted.drop(columns=['Open'])\n",
    "    y = data_shifted['diff_open'].rename(f\"t+{h}\").map(lambda x: 0 if x <= 0 else 1)\n",
    "    \n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOD DO prendre input date, changer facilement heure to minute!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data_test2(test_df, 5, h=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data_test(test_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing data and input_data function workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data, test=False):\n",
    "    \n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data_pp['open_diff'] = data_pp['Open'].diff()\n",
    "    data_pp = data_pp.dropna()\n",
    "    \n",
    "    return data_pp\n",
    "\n",
    "\n",
    "\n",
    "def input_data(data_pp, sample_size, shift_size, train_size, h=1, w=0):\n",
    "    \n",
    "    data_size = data_pp.shape[0]\n",
    "    sample = data.iloc[(data_size-sample_size-w):data_size-w] \n",
    "    \n",
    "    for i in range(0, shift_size):\n",
    "        sample[f't-{i}'] = sample['Open'].shift(i)\n",
    "    sample_shifted = sample.dropna() \n",
    "    \n",
    "    \n",
    "#    encoding???\n",
    "    sample['encoded'] = sample['Open_diff'].map(lambda x: 0 if x <= 0 else 1)\n",
    "    \n",
    "\n",
    "    X = sample_shifted.drop(columns=['Open'])\n",
    "    y = sample_shifted['Open'].shift(-h).rename(f\"t+{h}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    X_train = X.iloc[0:train_size]\n",
    "    y_train = y.iloc[0:train_size] #[0+h:train_size+h]\n",
    "    \n",
    "    X_test = X.iloc[(train_size+h-1):(sample_size-shift_size)]\n",
    "    y_test = y.iloc[(train_size+h-1):(sample_size-shift_size)] #[(train_size+(h*2)+1):(sample_size-shift_size)] \n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data, shift_size, h=1):\n",
    "    \n",
    "    data = data[2798176:4727776]\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data_pp = data_pp.dropna()\n",
    "    \n",
    "    data_pp['diff_Open'] = data_pp['Open'].diff(h)\n",
    "    data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    \n",
    "    data_pp[f\"t+{h}\"]= data_pp['diff_Open'].shift(-h)\n",
    "\n",
    "    \n",
    "    for i in range(0, shift_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna()\n",
    "    \n",
    "    \n",
    "    X = data_shifted.drop(columns=['Open', 'diff_Open', f\"t+{h}\"])\n",
    "    y = data_shifted[f\"t+{h}\"]\n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "\n",
    "    \n",
    "    return X, y, data_shifted\n",
    "\n",
    "\n",
    "def input_data(data, sample_size, shift_size, train_size, h=1, w=0):\n",
    "    \n",
    "    X, y, data_shifted = preprocessing_data(data, shift_size, h)\n",
    "    \n",
    "    data_size = data_shifted.shape[0]\n",
    "    sample = data_shifted.iloc[(data_size-sample_size-w):data_size-w]\n",
    "\n",
    "    X_train = X.iloc[0:train_size]\n",
    "    y_train = y.iloc[0:train_size] \n",
    "    \n",
    "    X_test = X.iloc[(train_size+h-1):(sample_size-shift_size)]\n",
    "    y_test = y.iloc[(train_size+h-1):(sample_size-shift_size)] \n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocessing_data(data, 60, h=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data[2798176:4727776]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[2798176:4727776]\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "data_pp = data[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "data_pp = data_pp.dropna()\n",
    "    \n",
    "data_pp['diff_Open'] = data_pp['Open'].diff()\n",
    "data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.Series(np.random.normal(size=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[d > 0] = 1\n",
    "d[d <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(d[0].rename('yo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[f\"t+{h}\"] = d['yo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"method to get the training data (or a portion of it) from google cloud bucket\"\"\"\n",
    "    # client = storage.Client()\n",
    "    # data = pd.read_csv(f\"gs://{BUCKET_NAME}/{BUCKET_TRAIN_DATA_PATH}\")\n",
    "    data = pd.read_csv('../raw_data/bitstampUSD.csv')\n",
    "    # data = pd.read_csv('gs://bitcoin-prediction-01/data/bitstampUSD.csv')\n",
    "    data = data[2798176:4727776]\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "    data = data[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data = data.dropna()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing_data(data, shift_size, h=1):\n",
    "    \n",
    "    data_pp = data[2798176:4727776]\n",
    "    data_pp['Timestamp'] = pd.to_datetime(data_pp['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data_pp[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data_pp\n",
    "    \n",
    "    data_pp['diff_Open'] = data_pp['Open'].diff(h)\n",
    "    data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    data_pp[f\"t+{h}\"] = data_pp['diff_Open'].shift(-h) \n",
    "    \n",
    "    for i in range(0, shift_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna()\n",
    "    \n",
    "    X = data_shifted.drop(columns=['Open', 'diff_Open', f\"t+{h}\"])\n",
    "    y = data_shifted[f\"t+{h}\"]\n",
    "    \n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    \n",
    "    return X, y, data_shifted\n",
    "\n",
    "\n",
    "def input_data(data, sample_size, shift_size, train_size, h=1, w=0):\n",
    "    \n",
    "    X, y, data_shifted = preprocessing_data(data, shift_size, h)\n",
    "    \n",
    "    data_size = data_shifted.shape[0]\n",
    "    sample_X = X.iloc[(data_size-sample_size-w):data_size-w]\n",
    "    sample_y = y.iloc[(data_size-sample_size-w):data_size-w]\n",
    "    \n",
    "    \n",
    "    X_train = sample_X.iloc[0:train_size]\n",
    "    y_train = sample_y.iloc[0:train_size] \n",
    "    X_test = sample_X.iloc[(train_size+h-1):(sample_size)]\n",
    "    y_test = sample_y.iloc[(train_size+h-1):(sample_size)] \n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = input_data(data, 1000, 5, 700, h=2, w=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data():\n",
    "#     \"\"\"method to get the training data (or a portion of it) from google cloud bucket\"\"\"\n",
    "#     # client = storage.Client()\n",
    "#     # data = pd.read_csv(f\"gs://{BUCKET_NAME}/{BUCKET_TRAIN_DATA_PATH}\")\n",
    "#     data = pd.read_csv('../raw_data/bitstampUSD.csv')\n",
    "#     # data = pd.read_csv('gs://bitcoin-prediction-01/data/bitstampUSD.csv')\n",
    "#     return data\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing_data(data, shift_size, h=1):\n",
    "    \n",
    "    data_pp = data[2798176:4727776]\n",
    "    data_pp['Timestamp'] = pd.to_datetime(data_pp['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data_pp[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data_pp\n",
    "    \n",
    "    data_pp['diff_Open'] = data_pp['Open'].diff(h)\n",
    "    data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    data_pp[f\"t+{h}\"] = data_pp['diff_Open'].shift(-h) \n",
    "    \n",
    "    for i in range(0, shift_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna()\n",
    "    \n",
    "    X = data_shifted.drop(columns=['Open', 'diff_Open', f\"t+{h}\"])\n",
    "    y = data_shifted[f\"t+{h}\"]\n",
    "    \n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    \n",
    "    return X, y, data_shifted\n",
    "\n",
    "\n",
    "def input_data(data, sample_size, shift_size, train_size, h=1, w=0):\n",
    "    \n",
    "    X, y, data_shifted = preprocessing_data(data, shift_size, h)\n",
    "    \n",
    "    data_size = data_shifted.shape[0]\n",
    "    test_size = sample_size - train_size\n",
    "    sample_X = X.iloc[data_size - (test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    sample_y = y.iloc[data_size - (test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    \n",
    "    \n",
    "    X_train = sample_X.iloc[0:train_size]\n",
    "    y_train = sample_y.iloc[0:train_size] \n",
    "    X_test = sample_X.iloc[(train_size+h-1):(sample_size)]\n",
    "    y_test = sample_y.iloc[(train_size+h-1):(sample_size)] \n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = input_data(data, 1000, 5, 700, h=2, w=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4727776 - 2798176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in range (17, 0):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = range(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round((1929600-200000)/100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = round((data_size-train_size)/test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing_data(data, shift_size, h=1):\n",
    "    \n",
    "    data_pp = data[2798176:4727776]\n",
    "    data_pp['Timestamp'] = pd.to_datetime(data_pp['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data_pp[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data_pp\n",
    "    \n",
    "    data_pp['diff_Open'] = data_pp['Open'].diff(h)\n",
    "    data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    data_pp[f\"t+{h}\"] = data_pp['diff_Open'].shift(-h) \n",
    "    \n",
    "    for i in range(0, shift_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna()\n",
    "    \n",
    "    X = data_shifted.drop(columns=['Open', 'diff_Open', f\"t+{h}\"])\n",
    "    y = data_shifted[f\"t+{h}\"]\n",
    "    \n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    \n",
    "    return X, y, data_shifted\n",
    "\n",
    "\n",
    "def preprocessing_data(data, shift_size, h=1):\n",
    "    data_pp = data[2798176:4727776].copy()\n",
    "    data_pp['Timestamp'] = pd.to_datetime(data_pp['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data_pp[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data_pp['diff_Open'] = data_pp['Open'].diff(h)\n",
    "    data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    data_pp[f\"t+{h}\"] = data_pp['diff_Open'].shift(-h)\n",
    "    for i in range(0, shift_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna()\n",
    "    X = data_shifted.drop(columns=['Open', 'diff_Open', f\"t+{h}\"])\n",
    "    y = data_shifted[f\"t+{h}\"].copy()\n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    return X, y, data_shifted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def input_data(data, sample_size, shift_size, train_size, h=1, w=0):\n",
    "    \n",
    "    X, y, data_shifted = preprocessing_data(data, shift_size, h)\n",
    "    \n",
    "    data_size = data_shifted.shape[0]\n",
    "    test_size = sample_size - train_size\n",
    "    sample_X = X.iloc[data_size - (test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    sample_y = y.iloc[data_size - (test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    \n",
    "    \n",
    "    X_train = sample_X.iloc[0:train_size]\n",
    "    y_train = sample_y.iloc[0:train_size] \n",
    "    X_test = sample_X.iloc[(train_size+h-1):(sample_size)]\n",
    "    y_test = sample_y.iloc[(train_size+h-1):(sample_size)] \n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def input_data(data, sample_size, shift_size, train_size, h=1, w=0):\n",
    "    X, y, data_shifted = preprocessing_data(data, shift_size, h)\n",
    "    data_size = data_shifted.shape[0]\n",
    "    test_size = sample_size - train_size\n",
    "    sample_X = X.iloc[data_size-(test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    sample_y = y.iloc[data_size-(test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    X_train = sample_X.iloc[0:train_size]\n",
    "    y_train = sample_y.iloc[0:train_size]\n",
    "    X_test = sample_X.iloc[(train_size+h-1):(sample_size-shift_size)]\n",
    "    y_test = sample_y.iloc[(train_size+h-1):(sample_size-shift_size)]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = input_data(data, 1000, 5, 700, h=2, w=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_cross_val_ridge(data, sample_size, train_size):\n",
    "    \n",
    "    r = round((data_size-train_size)/test_size)\n",
    "    intervals = range(0, r)\n",
    "    reversed_intervals = reversed(intervals)\n",
    "    results = []\n",
    "    \n",
    "    for w in reversed_intervals:\n",
    "        X_train, X_test, y_train, y_test = input_data(data, 1000, 5, 700, h=1, w=w)\n",
    "        score = ridge_classifier(X_train, X_test, y_train, y_test)\n",
    "        results.append(score)\n",
    "    return results, stats.mean(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
