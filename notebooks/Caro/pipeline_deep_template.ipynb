{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protective-sequence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T15:33:58.624633Z",
     "start_time": "2021-02-26T15:33:58.609857Z"
    },
    "id": "protective-sequence"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naughty-representative",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T15:34:00.366476Z",
     "start_time": "2021-02-26T15:33:58.960399Z"
    },
    "id": "naughty-representative"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "_XRZRFrfS-Ps",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XRZRFrfS-Ps",
    "outputId": "86e023f7-2a3b-4aff-c755-25672f0d5841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "CSbBE7d_S9cL",
   "metadata": {
    "id": "CSbBE7d_S9cL"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/bitstampUSD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Uh7q5eVUTUuA",
   "metadata": {
    "id": "Uh7q5eVUTUuA"
   },
   "outputs": [],
   "source": [
    "data = data[2798176:4727776].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Sd2JZ4K6Bzc3",
   "metadata": {
    "id": "Sd2JZ4K6Bzc3"
   },
   "outputs": [],
   "source": [
    "def preprocessing_data(data, features_size, h):\n",
    "        \n",
    "    data_pp = data.copy()\n",
    "    data_pp['diff_Open'] = data_pp['Open'].diff(h)\n",
    "    data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    data_pp[f\"t+{h}\"] = data_pp['diff_Open'].shift(-h)\n",
    "    \n",
    "    for i in range(0, features_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna()\n",
    "    \n",
    "    return data_shifted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "parallel-satellite",
   "metadata": {
    "id": "parallel-satellite"
   },
   "outputs": [],
   "source": [
    "def features_target(data_shifted, h):\n",
    "    \n",
    "    X = data_shifted.drop(columns=['Open', 'diff_Open', f\"t+{h}\"])\n",
    "    y = data_shifted[f\"t+{h}\"].copy()\n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    \n",
    "    data_size = data_shifted.shape[0]\n",
    "    \n",
    "    return X, y, data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "-gZgCS0zBwym",
   "metadata": {
    "id": "-gZgCS0zBwym"
   },
   "outputs": [],
   "source": [
    "def select_date(data, date_start, date_end):\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "    data = data[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "\n",
    "    if date_start != None:\n",
    "        if date_end != None:\n",
    "            data = data[date_start:date_end].copy()\n",
    "    else:\n",
    "        data = data.copy()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87kspYxEyAQ7",
   "metadata": {
    "id": "87kspYxEyAQ7"
   },
   "outputs": [],
   "source": [
    "def input_data(X, y, sample_size, data_size, train_size, test_size, h=1, w=0):    \n",
    " \n",
    "\n",
    "    sample_X = X.iloc[data_size-(test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    sample_y = y.iloc[data_size-(test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    \n",
    "    X_train = sample_X.iloc[0:train_size]\n",
    "    y_train = sample_y.iloc[0:train_size]\n",
    "    X_test = sample_X.iloc[(train_size+h-1):(sample_size)]\n",
    "    y_test = sample_y.iloc[(train_size+h-1):(sample_size)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "WozBM1xn0cb1",
   "metadata": {
    "id": "WozBM1xn0cb1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics as stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "TRl3HEsByA7P",
   "metadata": {
    "id": "TRl3HEsByA7P"
   },
   "outputs": [],
   "source": [
    "def predict_score(model_init, X_train, X_test, y_train, y_test):\n",
    "    model = model_init\n",
    "    model = model.fit(X_train, y_train)\n",
    "    results = model.predict(X_test)\n",
    "    score = model.score(X_test, y_test) \n",
    "    return score, model.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "xQyPS1DuyA-o",
   "metadata": {
    "id": "xQyPS1DuyA-o"
   },
   "outputs": [],
   "source": [
    "def cross_val(data, model_init=None,sample_size=1000, train_fraction=0.7, features_size=60, h=1, date_start=None, date_end=None):\n",
    "    \n",
    "    data = select_date(data, date_start, date_end)\n",
    "    data_shifted = preprocessing_data(data, features_size, h)\n",
    "    X, y, data_size = features_target(data_shifted, h)\n",
    "    train_size = int(train_fraction*sample_size)\n",
    "    test_size = sample_size - train_size\n",
    "    \n",
    "    \n",
    "    r = math.floor((data_size-sample_size)/test_size)\n",
    "    intervals = range(0, r)\n",
    "    reversed_intervals = reversed(intervals)\n",
    "    results = []\n",
    "    parameters = []\n",
    "    \n",
    "    for i in reversed_intervals:\n",
    "        X_train, X_test, y_train, y_test = input_data(X, y, sample_size, data_size, train_size, test_size, h, w=i)\n",
    "        score, params = predict_score(model_init, X_train, X_test, y_train, y_test)\n",
    "        results.append(score)\n",
    "        parameters.append(params)\n",
    "        # print(f\"fold {i} done\")\n",
    "\n",
    "    \n",
    "    return dict({'mean_score':np.around(np.mean(results), 2),\n",
    "                 'std':np.around(np.std(results), 2),   \n",
    "                 'score_min':np.around(np.amin(results), 2),\n",
    "                 'score_max':np.around(np.amax(results), 2), \n",
    "                 'n_fold':r}), np.around(np.mean(parameters, axis=0), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6maED2ro1tFV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6maED2ro1tFV",
    "outputId": "ab0193bf-1688-4d09-fa86-a65e0c88b6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memoized_property\n",
      "  Downloading https://files.pythonhosted.org/packages/70/db/23f8b5d86c9385299586c2469b58087f658f58eaeb414be0fd64cfd054e1/memoized-property-1.0.3.tar.gz\n",
      "Building wheels for collected packages: memoized-property\n",
      "  Building wheel for memoized-property (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for memoized-property: filename=memoized_property-1.0.3-py2.py3-none-any.whl size=4175 sha256=199aa0b3a9ed5dce0c7df34c040d8c91ab5074d5d00a8ec5a4c36bc4c6a8152b\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/d4/82/ace27b33257f5918497d20427c0ac31d39c76e68b44d593fe6\n",
      "Successfully built memoized-property\n",
      "Installing collected packages: memoized-property\n",
      "Successfully installed memoized-property-1.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install memoized_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "EGITxQ9911tO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EGITxQ9911tO",
    "outputId": "b4e21766-75de-47cc-8002-1d24e17afee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/dc/b45061f1cde42465f8ac1ebd86db3253a0e155619929bf1d6de271317c08/mlflow-1.14.1-py3-none-any.whl (14.2MB)\n",
      "\u001b[K     |████████████████████████████████| 14.2MB 319kB/s \n",
      "\u001b[?25hCollecting docker>=4.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/22/410313ad554477e87ec406d38d85f810e61ddb0d2fc44e64994857476de9/docker-4.4.4-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 48.1MB/s \n",
      "\u001b[?25hCollecting prometheus-flask-exporter\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/d5/8a046d683c2cc084b6a502812827ede69b1064f95d93f94b83f809b21723/prometheus_flask_exporter-0.18.1.tar.gz\n",
      "Collecting gitpython>=2.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 40.6MB/s \n",
      "\u001b[?25hCollecting gunicorn; platform_system != \"Windows\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 6.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.5)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.1)\n",
      "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.13)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2018.9)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.19.5)\n",
      "Collecting querystring-parser\n",
      "  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n",
      "Collecting databricks-cli>=0.8.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/44/69bb20181e59c4ccca22bf8444342994270e2e87111ab07f2b8d19a8c1b2/databricks-cli-0.14.2.tar.gz (54kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 5.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
      "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
      "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.23)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.3)\n",
      "Collecting alembic<=1.4.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 43.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.12.4)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from docker>=4.0.0->mlflow) (1.15.0)\n",
      "Collecting websocket-client>=0.32.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: prometheus_client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.9.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 5.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn; platform_system != \"Windows\"->mlflow) (54.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mlflow) (2.8.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
      "Collecting Mako\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/db/2d2d88b924aa4674a080aae83b59ea19d593250bfe5ed789947c21736785/Mako-1.1.4.tar.gz (479kB)\n",
      "\u001b[K     |████████████████████████████████| 481kB 48.4MB/s \n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask->mlflow) (1.1.1)\n",
      "Building wheels for collected packages: prometheus-flask-exporter, databricks-cli, alembic, Mako\n",
      "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-cp37-none-any.whl size=17159 sha256=ed63896471a2510cb098d415f41415adef820a4ec3212a4f85c899eab74ee05d\n",
      "  Stored in directory: /root/.cache/pip/wheels/b4/1f/b8/66bd9bc3a9d6c6987ff6c4dfeb6f1fe97b5a0e5ed5849c0437\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.14.2-cp37-none-any.whl size=100732 sha256=c3bf1b78686288e562df4f4e4f4e7717dca0a9067d10cf772476271228ced124\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/66/0a/72e45560f269c38892b8f42169a22403ff46e3811f2c82c3a6\n",
      "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=1c9d3286ff2f6558a7fbfe3b67ff4383b45bc80b92e0d8d5f237adac46bbd8e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
      "  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Mako: filename=Mako-1.1.4-py2.py3-none-any.whl size=75675 sha256=13b2276874b7df33e004ddfe5b5f10d321aada784380a612120a3a2c461b4d6d\n",
      "  Stored in directory: /root/.cache/pip/wheels/ad/10/d3/aeb26e20d19045e2a68e5d3cbb57432e11b5d9c92c99f98d47\n",
      "Successfully built prometheus-flask-exporter databricks-cli alembic Mako\n",
      "Installing collected packages: websocket-client, docker, prometheus-flask-exporter, smmap, gitdb, gitpython, gunicorn, querystring-parser, databricks-cli, Mako, python-editor, alembic, mlflow\n",
      "Successfully installed Mako-1.1.4 alembic-1.4.1 databricks-cli-0.14.2 docker-4.4.4 gitdb-4.0.5 gitpython-3.1.14 gunicorn-20.0.4 mlflow-1.14.1 prometheus-flask-exporter-0.18.1 python-editor-1.0.4 querystring-parser-1.2.4 smmap-3.0.5 websocket-client-0.58.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "xcjgRHvtyBBr",
   "metadata": {
    "id": "xcjgRHvtyBBr"
   },
   "outputs": [],
   "source": [
    "from memoized_property import memoized_property\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "class MLFlowBase():\n",
    "\n",
    "    def __init__(self, experiment_name, MLFLOW_URI):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.MLFLOW_URI = MLFLOW_URI\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_client(self):\n",
    "        mlflow.set_tracking_uri(self.MLFLOW_URI)\n",
    "        return MlflowClient()\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_experiment_id(self):\n",
    "        try:\n",
    "            return self.mlflow_client \\\n",
    "                .create_experiment(self.experiment_name)\n",
    "        except BaseException:\n",
    "            return self.mlflow_client \\\n",
    "                .get_experiment_by_name(self.experiment_name).experiment_id\n",
    "\n",
    "    def mlflow_create_run(self):\n",
    "        self.mlflow_run = self.mlflow_client \\\n",
    "            .create_run(self.mlflow_experiment_id)\n",
    "\n",
    "    def mlflow_log_param(self, key, value):\n",
    "        self.mlflow_client \\\n",
    "            .log_param(self.mlflow_run.info.run_id, key, value)\n",
    "\n",
    "    def mlflow_log_metric(self, key, value):\n",
    "        self.mlflow_client \\\n",
    "            .log_metric(self.mlflow_run.info.run_id, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2P81nWE2yBEm",
   "metadata": {
    "id": "2P81nWE2yBEm"
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "IrXkKNRByBHX",
   "metadata": {
    "id": "IrXkKNRByBHX"
   },
   "outputs": [],
   "source": [
    "class Trainer(MLFlowBase):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"[FR] [Paris] [nhuberde] bitcoin project\",\n",
    "            \"https://mlflow.lewagon.co\")\n",
    "            \n",
    "    # def train(self, trainer_params, hyper_params):\n",
    "    def train(self, trainer_params, data):\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        # step 1 : iterate on trainer params\n",
    "        for param_combination in product(*trainer_params.values()):\n",
    "\n",
    "            exp_params = dict(zip(trainer_params.keys(), param_combination))\n",
    "\n",
    "            # print(exp_params)\n",
    "\n",
    "            # step 2 : iterate on models\n",
    "            # for model_name, model_hparams in hyper_params.items():\n",
    "\n",
    "                # print(f\"model name {model_name}\")\n",
    "\n",
    "                # step 3 : iterate on model hyperparams\n",
    "                # for hparam_combi in product(*model_hparams.values()):\n",
    "\n",
    "                #     hexp_params = dict(zip(model_hparams.keys(), hparam_combi))\n",
    "\n",
    "                    # print(hexp_params)\n",
    "\n",
    "                    # mais avec quoi je train ?\n",
    "            i += 1\n",
    "            print(f\"\\nexperiment #{i}:\")\n",
    "            print(exp_params)\n",
    "            # print(f\"model name {model_name}\")\n",
    "            # print(hexp_params)\n",
    "\n",
    "            # TODO: train with trainer params + model + hyperparams\n",
    "\n",
    "            # => appeler la crossval\n",
    "            # data = get_data()\n",
    "            results, parameters = cross_val(data, **exp_params)\n",
    "\n",
    "\n",
    "            # create a mlflow training\n",
    "            self.mlflow_create_run()  # create one training\n",
    "\n",
    "            # log trainer params\n",
    "            for key, value in exp_params.items():\n",
    "                self.mlflow_log_param(key, value)\n",
    "                \n",
    "            # then log buddy_name on mlflow\n",
    "            self.mlflow_log_param(\"buddy_name\", {buddy_name})\n",
    "\n",
    "            # log params\n",
    "            # self.mlflow_log_param(\"model\", model_name)\n",
    "\n",
    "            # log model hyper params\n",
    "            # for key, value in hexp_params.items():\n",
    "            #     self.mlflow_log_param(key, value)\n",
    "\n",
    "            # push metrics to mlflow\n",
    "            self.mlflow_log_metric(\"mean_score\", results['mean_score'])\n",
    "            self.mlflow_log_metric(\"std\", results['std'])\n",
    "            self.mlflow_log_metric(\"score_min\", results['score_min'])\n",
    "            self.mlflow_log_metric(\"score_max\", results['score_max'])\n",
    "            for p in range(parameters.shape[1]):\n",
    "                self.mlflow_log_metric(f\"coef_feature {p}\", parameters[0,p])\n",
    "            \n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cw_4mJrG3rlE",
   "metadata": {
    "id": "cw_4mJrG3rlE"
   },
   "outputs": [],
   "source": [
    "buddy_name = 'Caroline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4zspARyg4Ly-",
   "metadata": {
    "id": "4zspARyg4Ly-"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4wim0FQ6yBKJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wim0FQ6yBKJ",
    "outputId": "e5c2413e-00f4-423f-8a5c-e5993983ab8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "experiment #1:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 1440, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #2:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 10080, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #3:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 14400, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #4:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 21600, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #5:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 43200, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #6:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 86400, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #7:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 129600, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n"
     ]
    }
   ],
   "source": [
    "trainer_params = dict(\n",
    "    model_init=[RidgeClassifier()],\n",
    "    sample_size=[1440, 10080, 14400, 21600, 43200, 86400, 129600],\n",
    "    train_fraction=[0.7],\n",
    "    features_size=[60],\n",
    "    h=[10],\n",
    "    date_start=[\"2020\"],\n",
    "    date_end=[\"2020\"],\n",
    ")\n",
    "\n",
    "trainer = Trainer()\n",
    "models = trainer.train(trainer_params, data)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nNJSoSwQ0KSJ",
   "metadata": {
    "id": "nNJSoSwQ0KSJ"
   },
   "outputs": [],
   "source": [
    "def predict_score_deep(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model = Sequential()\n",
    "    es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "    \n",
    "    model.add(GRU(units = 30, activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(units = 40, return_sequences = True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(GRU(units = 10,  activation='tanh', return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 5, activation='relu'))\n",
    "    model.add(Dense(units = 1, activation='sigmoid'))\n",
    "    # Compiling the RNN\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    # Fitting the RNN to the Training set\n",
    "    model.fit(X_train, y_train, validation_split=0.2, epochs = 3, batch_size = 32, callbacks=[es])\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return score[1] #attention score[0] loss à return also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ajIypFa70LFF",
   "metadata": {
    "id": "ajIypFa70LFF"
   },
   "outputs": [],
   "source": [
    "def deep(data, sample_size=1000, train_fraction=0.7, features_size=60, h=1, date_start=None, date_end=None):\n",
    "    \n",
    "    data = select_date(data, date_start, date_end)\n",
    "    data_shifted = preprocessing_data(data, features_size, h)\n",
    "    X, y, data_size = features_target(data_shifted, h)\n",
    "    train_size = int(train_fraction*sample_size)\n",
    "    test_size = sample_size - train_size\n",
    "    \n",
    "    r = math.floor((data_size-train_size)/test_size)\n",
    "    intervals = range(0, r)\n",
    "    reversed_intervals = reversed(intervals)\n",
    "    results = []\n",
    "    \n",
    "    for i in reversed_intervals:\n",
    "        X_train, X_test, y_train, y_test = input_data(X, y, sample_size, data_size, train_size, test_size, h, w=i)\n",
    "  \n",
    "        X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "        X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "            \n",
    "        score = predict_score_deep(X_train, X_test, y_train, y_test)\n",
    "        results.append(score)\n",
    "    \n",
    "    return dict({'mean_score':round(stats.mean(results),2),\n",
    "                 'std':round(stats.stdev(results),2),\n",
    "                 'score_min':round(min(results),2),\n",
    "                 'score_max':round(max(results),2),\n",
    "                 'n_fold':r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "T4qTBvzB2Yhi",
   "metadata": {
    "id": "T4qTBvzB2Yhi"
   },
   "outputs": [],
   "source": [
    "class Trainer2(MLFlowBase):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"[FR] [Paris] [nhuberde] bitcoin project\",\n",
    "            \"https://mlflow.lewagon.co\")\n",
    "            \n",
    "    # def train(self, trainer_params, hyper_params):\n",
    "    def train(self, trainer_params, data):\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        # step 1 : iterate on trainer params\n",
    "        for param_combination in product(*trainer_params.values()):\n",
    "\n",
    "            exp_params = dict(zip(trainer_params.keys(), param_combination))\n",
    "\n",
    "            # print(exp_params)\n",
    "\n",
    "            # step 2 : iterate on models\n",
    "            # for model_name, model_hparams in hyper_params.items():\n",
    "\n",
    "                # print(f\"model name {model_name}\")\n",
    "\n",
    "                # step 3 : iterate on model hyperparams\n",
    "                # for hparam_combi in product(*model_hparams.values()):\n",
    "\n",
    "                #     hexp_params = dict(zip(model_hparams.keys(), hparam_combi))\n",
    "\n",
    "                    # print(hexp_params)\n",
    "\n",
    "                    # mais avec quoi je train ?\n",
    "            i += 1\n",
    "            print(f\"\\nexperiment #{i}:\")\n",
    "            print(exp_params)\n",
    "            # print(f\"model name {model_name}\")\n",
    "            # print(hexp_params)\n",
    "\n",
    "            # TODO: train with trainer params + model + hyperparams\n",
    "\n",
    "            # => appeler la crossval\n",
    "            # data = get_data()\n",
    "            results = deep(data, **exp_params)\n",
    "\n",
    "\n",
    "            # create a mlflow training\n",
    "            self.mlflow_create_run()  # create one training\n",
    "\n",
    "            # log trainer params\n",
    "            for key, value in exp_params.items():\n",
    "                self.mlflow_log_param(key, value)\n",
    "                \n",
    "            # then log buddy_name on mlflow\n",
    "            self.mlflow_log_param(\"buddy_name\", {buddy_name})\n",
    "            self.mlflow_log_param(\"model_type\", \"GRU\")\n",
    "\n",
    "            # log params\n",
    "            # self.mlflow_log_param(\"model\", model_name)\n",
    "\n",
    "            # log model hyper params\n",
    "            # for key, value in hexp_params.items():\n",
    "            #     self.mlflow_log_param(key, value)\n",
    "\n",
    "            # push metrics to mlflow\n",
    "            self.mlflow_log_metric(\"mean_score\", results['mean_score'])\n",
    "            self.mlflow_log_metric(\"std\", results['std'])\n",
    "            self.mlflow_log_metric(\"score_min\", results['score_min'])\n",
    "            self.mlflow_log_metric(\"score_max\", results['score_max'])\n",
    "            self.mlflow_log_metric(\"n_fold\", results['n_fold'])\n",
    "            \n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "Jl__fA0q4Cce",
   "metadata": {
    "id": "Jl__fA0q4Cce"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Eg9mNnhW0LI8",
   "metadata": {
    "id": "Eg9mNnhW0LI8"
   },
   "outputs": [],
   "source": [
    "results = deep(data, sample_size=1440, train_fraction=0.7, features_size=60, h=1, date_start=\"2020-10-01\", date_end=\"2020-10-07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "lHsIZuXR0LMW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHsIZuXR0LMW",
    "outputId": "746e6f36-8f69-416f-969c-40e55af90e85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_score': 0.51,\n",
       " 'n_fold': 20,\n",
       " 'score_max': 0.61,\n",
       " 'score_min': 0.47,\n",
       " 'std': 0.03}"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "jjSi59gH0LO6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjSi59gH0LO6",
    "outputId": "bfb9606f-db05-4c17-9033-3190e619792a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "experiment #1:\n",
      "{'sample_size': 1440, 'train_fraction': 0.7, 'features_size': 60, 'h': 1, 'date_start': '2020-10-01', 'date_end': '2020-10-07'}\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 78ms/step - loss: 0.6929 - accuracy: 0.5298 - val_loss: 0.6968 - val_accuracy: 0.4752\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6888 - accuracy: 0.5559 - val_loss: 0.6966 - val_accuracy: 0.4752\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6893 - accuracy: 0.5562 - val_loss: 0.6973 - val_accuracy: 0.4752\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 82ms/step - loss: 0.7268 - accuracy: 0.4835 - val_loss: 0.6942 - val_accuracy: 0.4802\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6965 - accuracy: 0.4991 - val_loss: 0.6936 - val_accuracy: 0.4802\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6944 - accuracy: 0.4971 - val_loss: 0.6937 - val_accuracy: 0.4802\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 79ms/step - loss: 0.7005 - accuracy: 0.4973 - val_loss: 0.6921 - val_accuracy: 0.5297\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6933 - accuracy: 0.5071 - val_loss: 0.6932 - val_accuracy: 0.4713\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6940 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5248\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 80ms/step - loss: 0.7514 - accuracy: 0.5059 - val_loss: 0.6996 - val_accuracy: 0.4802\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.7019 - accuracy: 0.4963 - val_loss: 0.6989 - val_accuracy: 0.4802\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6997 - accuracy: 0.4855 - val_loss: 0.6947 - val_accuracy: 0.4802\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 81ms/step - loss: 0.7296 - accuracy: 0.4828 - val_loss: 0.7115 - val_accuracy: 0.4356\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6998 - accuracy: 0.5055 - val_loss: 0.6970 - val_accuracy: 0.4356\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6964 - accuracy: 0.5015 - val_loss: 0.6991 - val_accuracy: 0.4356\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 79ms/step - loss: 0.7000 - accuracy: 0.5219 - val_loss: 0.6924 - val_accuracy: 0.5248\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6933 - accuracy: 0.5236 - val_loss: 0.6926 - val_accuracy: 0.5239\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6942 - accuracy: 0.5061 - val_loss: 0.6929 - val_accuracy: 0.5198\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 84ms/step - loss: 0.7041 - accuracy: 0.4989 - val_loss: 0.6991 - val_accuracy: 0.4554\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6960 - accuracy: 0.5041 - val_loss: 0.6973 - val_accuracy: 0.4554\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6931 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5446\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 81ms/step - loss: 0.6935 - accuracy: 0.5253 - val_loss: 0.6932 - val_accuracy: 0.4901\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6935 - accuracy: 0.5062 - val_loss: 0.6932 - val_accuracy: 0.4901\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.6933 - accuracy: 0.4739 - val_loss: 0.6932 - val_accuracy: 0.4901\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 87ms/step - loss: 0.6968 - accuracy: 0.4980 - val_loss: 0.6933 - val_accuracy: 0.4356\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6942 - accuracy: 0.4891 - val_loss: 0.6934 - val_accuracy: 0.4356\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6935 - accuracy: 0.5108 - val_loss: 0.6934 - val_accuracy: 0.4356\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 83ms/step - loss: 0.6959 - accuracy: 0.5169 - val_loss: 0.6903 - val_accuracy: 0.5446\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6903 - accuracy: 0.5500 - val_loss: 0.6907 - val_accuracy: 0.5446\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6929 - accuracy: 0.5303 - val_loss: 0.6909 - val_accuracy: 0.5446\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 82ms/step - loss: 0.7047 - accuracy: 0.4983 - val_loss: 0.6915 - val_accuracy: 0.5297\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6903 - accuracy: 0.5476 - val_loss: 0.6933 - val_accuracy: 0.4812\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6938 - accuracy: 0.5179 - val_loss: 0.6931 - val_accuracy: 0.5297\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 94ms/step - loss: 0.7463 - accuracy: 0.4657 - val_loss: 0.6841 - val_accuracy: 0.5670\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7046 - accuracy: 0.5046 - val_loss: 0.6936 - val_accuracy: 0.5416\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7042 - accuracy: 0.4950 - val_loss: 0.6848 - val_accuracy: 0.5693\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 75ms/step - loss: 0.6970 - accuracy: 0.5052 - val_loss: 0.7006 - val_accuracy: 0.4802\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6922 - accuracy: 0.5375 - val_loss: 0.6980 - val_accuracy: 0.4802\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6895 - accuracy: 0.5507 - val_loss: 0.6972 - val_accuracy: 0.4802\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 84ms/step - loss: 0.7165 - accuracy: 0.4922 - val_loss: 0.7077 - val_accuracy: 0.4901\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.7018 - accuracy: 0.5193 - val_loss: 0.6981 - val_accuracy: 0.4901\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6973 - accuracy: 0.5123 - val_loss: 0.6947 - val_accuracy: 0.4901\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 84ms/step - loss: 0.7203 - accuracy: 0.4768 - val_loss: 0.6980 - val_accuracy: 0.4554\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6979 - accuracy: 0.4822 - val_loss: 0.6922 - val_accuracy: 0.5446\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6936 - accuracy: 0.5094 - val_loss: 0.6921 - val_accuracy: 0.5446\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 87ms/step - loss: 0.7005 - accuracy: 0.5269 - val_loss: 0.6834 - val_accuracy: 0.5941\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.7048 - accuracy: 0.5011 - val_loss: 0.6843 - val_accuracy: 0.5941\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6983 - accuracy: 0.5135 - val_loss: 0.6859 - val_accuracy: 0.5941\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 82ms/step - loss: 0.6968 - accuracy: 0.5426 - val_loss: 0.6901 - val_accuracy: 0.5396\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6885 - accuracy: 0.5568 - val_loss: 0.6904 - val_accuracy: 0.5396\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6879 - accuracy: 0.5558 - val_loss: 0.6905 - val_accuracy: 0.5396\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 85ms/step - loss: 0.6928 - accuracy: 0.5365 - val_loss: 0.6934 - val_accuracy: 0.5050\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6940 - accuracy: 0.5130 - val_loss: 0.6934 - val_accuracy: 0.5050\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6893 - accuracy: 0.5586 - val_loss: 0.6935 - val_accuracy: 0.5050\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 78ms/step - loss: 0.7075 - accuracy: 0.5106 - val_loss: 0.6958 - val_accuracy: 0.5050\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.7013 - accuracy: 0.5034 - val_loss: 0.6933 - val_accuracy: 0.4967\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6979 - accuracy: 0.5019 - val_loss: 0.6933 - val_accuracy: 0.4965\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 81ms/step - loss: 0.6941 - accuracy: 0.4864 - val_loss: 0.6930 - val_accuracy: 0.5198\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6933 - accuracy: 0.4939 - val_loss: 0.6928 - val_accuracy: 0.5198\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6927 - accuracy: 0.5267 - val_loss: 0.6929 - val_accuracy: 0.5198\n"
     ]
    }
   ],
   "source": [
    "trainer_params2 = dict(\n",
    "    sample_size=[1440],\n",
    "    train_fraction=[0.7],\n",
    "    features_size=[60],\n",
    "    h=[1],\n",
    "    date_start=[\"2020-10-01\"],\n",
    "    date_end=[\"2020-10-07\"],\n",
    ")\n",
    "\n",
    "trainer2 = Trainer2()\n",
    "trainer2.train(trainer_params2, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "PFOnRz3T9gX9",
   "metadata": {
    "id": "PFOnRz3T9gX9"
   },
   "outputs": [],
   "source": [
    "# data2 = select_date(data, date_start=None, date_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cftLHVz_0LR2",
   "metadata": {
    "id": "cftLHVz_0LR2"
   },
   "outputs": [],
   "source": [
    "# data_shifted = preprocessing_data(data2, features_size=120, h=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3Z2Apiir0LYh",
   "metadata": {
    "id": "3Z2Apiir0LYh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
