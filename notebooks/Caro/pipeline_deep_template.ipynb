{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protective-sequence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T15:33:58.624633Z",
     "start_time": "2021-02-26T15:33:58.609857Z"
    },
    "id": "protective-sequence"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install memoized_property\n",
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-guatemala",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naughty-representative",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T15:34:00.366476Z",
     "start_time": "2021-02-26T15:33:58.960399Z"
    },
    "id": "naughty-representative"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stats\n",
    "import math\n",
    "from memoized_property import memoized_property\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from itertools import product\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "_XRZRFrfS-Ps",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XRZRFrfS-Ps",
    "outputId": "86e023f7-2a3b-4aff-c755-25672f0d5841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-living",
   "metadata": {},
   "source": [
    "# Data import + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "CSbBE7d_S9cL",
   "metadata": {
    "id": "CSbBE7d_S9cL"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/bitstampUSD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Uh7q5eVUTUuA",
   "metadata": {
    "id": "Uh7q5eVUTUuA"
   },
   "outputs": [],
   "source": [
    "data = data[2798176:4727776].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Sd2JZ4K6Bzc3",
   "metadata": {
    "id": "Sd2JZ4K6Bzc3"
   },
   "outputs": [],
   "source": [
    "def preprocessing_data(data, features_size, h):\n",
    "        \n",
    "    data_pp = data.copy()\n",
    "    data_pp['diff_Open'] = data_pp['Open'].diff(h)\n",
    "    data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    data_pp[f\"t+{h}\"] = data_pp['diff_Open'].shift(-h)\n",
    "    \n",
    "    for i in range(0, features_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna()\n",
    "    \n",
    "    return data_shifted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-debut",
   "metadata": {},
   "source": [
    "# Feature building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "parallel-satellite",
   "metadata": {
    "id": "parallel-satellite"
   },
   "outputs": [],
   "source": [
    "def features_target(data_shifted, h):\n",
    "    \n",
    "    X = data_shifted.drop(columns=['Open', 'diff_Open', f\"t+{h}\"])\n",
    "    y = data_shifted[f\"t+{h}\"].copy()\n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    \n",
    "    data_size = data_shifted.shape[0]\n",
    "    \n",
    "    return X, y, data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-egypt",
   "metadata": {},
   "source": [
    "# Date formatting + selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "-gZgCS0zBwym",
   "metadata": {
    "id": "-gZgCS0zBwym"
   },
   "outputs": [],
   "source": [
    "def select_date(data, date_start, date_end):\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "    data = data[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "\n",
    "    if date_start != None:\n",
    "        if date_end != None:\n",
    "            data = data[date_start:date_end].copy()\n",
    "    else:\n",
    "        data = data.copy()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87kspYxEyAQ7",
   "metadata": {
    "id": "87kspYxEyAQ7"
   },
   "outputs": [],
   "source": [
    "def input_data(X, y, sample_size, data_size, train_size, test_size, h=1, w=0):    \n",
    " \n",
    "\n",
    "    sample_X = X.iloc[data_size-(test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    sample_y = y.iloc[data_size-(test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    \n",
    "    X_train = sample_X.iloc[0:train_size]\n",
    "    y_train = sample_y.iloc[0:train_size]\n",
    "    X_test = sample_X.iloc[(train_size+h-1):(sample_size)]\n",
    "    y_test = sample_y.iloc[(train_size+h-1):(sample_size)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "TRl3HEsByA7P",
   "metadata": {
    "id": "TRl3HEsByA7P"
   },
   "outputs": [],
   "source": [
    "def predict_score(model_init, X_train, X_test, y_train, y_test):\n",
    "    model = model_init\n",
    "    model = model.fit(X_train, y_train)\n",
    "    results = model.predict(X_test)\n",
    "    score = model.score(X_test, y_test) \n",
    "    return score, model.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "xQyPS1DuyA-o",
   "metadata": {
    "id": "xQyPS1DuyA-o"
   },
   "outputs": [],
   "source": [
    "def cross_val(data, model_init=None,sample_size=1000, train_fraction=0.7, features_size=60, h=1, date_start=None, date_end=None):\n",
    "    \n",
    "    data = select_date(data, date_start, date_end)\n",
    "    data_shifted = preprocessing_data(data, features_size, h)\n",
    "    X, y, data_size = features_target(data_shifted, h)\n",
    "    train_size = int(train_fraction*sample_size)\n",
    "    test_size = sample_size - train_size\n",
    "    \n",
    "    \n",
    "    r = math.floor((data_size-sample_size)/test_size)\n",
    "    intervals = range(0, r)\n",
    "    reversed_intervals = reversed(intervals)\n",
    "    results = []\n",
    "    parameters = []\n",
    "    \n",
    "    for i in reversed_intervals:\n",
    "        X_train, X_test, y_train, y_test = input_data(X, y, sample_size, data_size, train_size, test_size, h, w=i)\n",
    "        score, params = predict_score(model_init, X_train, X_test, y_train, y_test)\n",
    "        results.append(score)\n",
    "        parameters.append(params)\n",
    "        # print(f\"fold {i} done\")\n",
    "\n",
    "    \n",
    "    return dict({'mean_score':np.around(np.mean(results), 2),\n",
    "                 'std':np.around(np.std(results), 2),   \n",
    "                 'score_min':np.around(np.amin(results), 2),\n",
    "                 'score_max':np.around(np.amax(results), 2), \n",
    "                 'n_fold':r}), np.around(np.mean(parameters, axis=0), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "xcjgRHvtyBBr",
   "metadata": {
    "id": "xcjgRHvtyBBr"
   },
   "outputs": [],
   "source": [
    "class MLFlowBase():\n",
    "\n",
    "    def __init__(self, experiment_name, MLFLOW_URI):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.MLFLOW_URI = MLFLOW_URI\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_client(self):\n",
    "        mlflow.set_tracking_uri(self.MLFLOW_URI)\n",
    "        return MlflowClient()\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_experiment_id(self):\n",
    "        try:\n",
    "            return self.mlflow_client \\\n",
    "                .create_experiment(self.experiment_name)\n",
    "        except BaseException:\n",
    "            return self.mlflow_client \\\n",
    "                .get_experiment_by_name(self.experiment_name).experiment_id\n",
    "\n",
    "    def mlflow_create_run(self):\n",
    "        self.mlflow_run = self.mlflow_client \\\n",
    "            .create_run(self.mlflow_experiment_id)\n",
    "\n",
    "    def mlflow_log_param(self, key, value):\n",
    "        self.mlflow_client \\\n",
    "            .log_param(self.mlflow_run.info.run_id, key, value)\n",
    "\n",
    "    def mlflow_log_metric(self, key, value):\n",
    "        self.mlflow_client \\\n",
    "            .log_metric(self.mlflow_run.info.run_id, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "IrXkKNRByBHX",
   "metadata": {
    "id": "IrXkKNRByBHX"
   },
   "outputs": [],
   "source": [
    "class Trainer(MLFlowBase):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"[FR] [Paris] [nhuberde] bitcoin project\",\n",
    "            \"https://mlflow.lewagon.co\")\n",
    "            \n",
    "    # def train(self, trainer_params, hyper_params):\n",
    "    def train(self, trainer_params, data):\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        # step 1 : iterate on trainer params\n",
    "        for param_combination in product(*trainer_params.values()):\n",
    "\n",
    "            exp_params = dict(zip(trainer_params.keys(), param_combination))\n",
    "\n",
    "            # print(exp_params)\n",
    "\n",
    "            # step 2 : iterate on models\n",
    "            # for model_name, model_hparams in hyper_params.items():\n",
    "\n",
    "                # print(f\"model name {model_name}\")\n",
    "\n",
    "                # step 3 : iterate on model hyperparams\n",
    "                # for hparam_combi in product(*model_hparams.values()):\n",
    "\n",
    "                #     hexp_params = dict(zip(model_hparams.keys(), hparam_combi))\n",
    "\n",
    "                    # print(hexp_params)\n",
    "\n",
    "                    # mais avec quoi je train ?\n",
    "            i += 1\n",
    "            print(f\"\\nexperiment #{i}:\")\n",
    "            print(exp_params)\n",
    "            # print(f\"model name {model_name}\")\n",
    "            # print(hexp_params)\n",
    "\n",
    "            # TODO: train with trainer params + model + hyperparams\n",
    "\n",
    "            # => appeler la crossval\n",
    "            # data = get_data()\n",
    "            results, parameters = cross_val(data, **exp_params)\n",
    "\n",
    "\n",
    "            # create a mlflow training\n",
    "            self.mlflow_create_run()  # create one training\n",
    "\n",
    "            # log trainer params\n",
    "            for key, value in exp_params.items():\n",
    "                self.mlflow_log_param(key, value)\n",
    "                \n",
    "            # then log buddy_name on mlflow\n",
    "            self.mlflow_log_param(\"buddy_name\", {buddy_name})\n",
    "\n",
    "            # log params\n",
    "            # self.mlflow_log_param(\"model\", model_name)\n",
    "\n",
    "            # log model hyper params\n",
    "            # for key, value in hexp_params.items():\n",
    "            #     self.mlflow_log_param(key, value)\n",
    "\n",
    "            # push metrics to mlflow\n",
    "            self.mlflow_log_metric(\"mean_score\", results['mean_score'])\n",
    "            self.mlflow_log_metric(\"std\", results['std'])\n",
    "            self.mlflow_log_metric(\"score_min\", results['score_min'])\n",
    "            self.mlflow_log_metric(\"score_max\", results['score_max'])\n",
    "            for p in range(parameters.shape[1]):\n",
    "                self.mlflow_log_metric(f\"coef_feature {p}\", parameters[0,p])\n",
    "            \n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cw_4mJrG3rlE",
   "metadata": {
    "id": "cw_4mJrG3rlE"
   },
   "outputs": [],
   "source": [
    "buddy_name = 'Caroline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4wim0FQ6yBKJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wim0FQ6yBKJ",
    "outputId": "e5c2413e-00f4-423f-8a5c-e5993983ab8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "experiment #1:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 1440, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #2:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 10080, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #3:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 14400, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #4:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 21600, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #5:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 43200, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #6:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 86400, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n",
      "\n",
      "experiment #7:\n",
      "{'model_init': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'sample_size': 129600, 'train_fraction': 0.7, 'features_size': 60, 'h': 10, 'date_start': '2020', 'date_end': '2020'}\n"
     ]
    }
   ],
   "source": [
    "trainer_params = dict(\n",
    "    model_init=[RidgeClassifier()],\n",
    "    sample_size=[1440, 10080, 14400, 21600, 43200, 86400, 129600],\n",
    "    train_fraction=[0.7],\n",
    "    features_size=[60],\n",
    "    h=[10],\n",
    "    date_start=[\"2020\"],\n",
    "    date_end=[\"2020\"],\n",
    ")\n",
    "\n",
    "trainer = Trainer()\n",
    "models = trainer.train(trainer_params, data)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nNJSoSwQ0KSJ",
   "metadata": {
    "id": "nNJSoSwQ0KSJ"
   },
   "outputs": [],
   "source": [
    "def predict_score_deep(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model = Sequential()\n",
    "    es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "    \n",
    "    model.add(GRU(units = 30, activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(units = 40, return_sequences = True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(GRU(units = 10,  activation='tanh', return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 5, activation='relu'))\n",
    "    model.add(Dense(units = 1, activation='sigmoid'))\n",
    "    # Compiling the RNN\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    # Fitting the RNN to the Training set\n",
    "    model.fit(X_train, y_train, validation_split=0.2, epochs = 3, batch_size = 32, callbacks=[es])\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return score[1] #attention score[0] loss Ã  return also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ajIypFa70LFF",
   "metadata": {
    "id": "ajIypFa70LFF"
   },
   "outputs": [],
   "source": [
    "def deep(data, sample_size=1000, train_fraction=0.7, features_size=60, h=1, date_start=None, date_end=None):\n",
    "    \n",
    "    data = select_date(data, date_start, date_end)\n",
    "    data_shifted = preprocessing_data(data, features_size, h)\n",
    "    X, y, data_size = features_target(data_shifted, h)\n",
    "    train_size = int(train_fraction*sample_size)\n",
    "    test_size = sample_size - train_size\n",
    "    \n",
    "    r = math.floor((data_size-train_size)/test_size)\n",
    "    intervals = range(0, r)\n",
    "    reversed_intervals = reversed(intervals)\n",
    "    results = []\n",
    "    \n",
    "    for i in reversed_intervals:\n",
    "        X_train, X_test, y_train, y_test = input_data(X, y, sample_size, data_size, train_size, test_size, h, w=i)\n",
    "  \n",
    "        X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "        X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "            \n",
    "        score = predict_score_deep(X_train, X_test, y_train, y_test)\n",
    "        results.append(score)\n",
    "    \n",
    "    return dict({'mean_score':round(stats.mean(results),2),\n",
    "                 'std':round(stats.stdev(results),2),\n",
    "                 'score_min':round(min(results),2),\n",
    "                 'score_max':round(max(results),2),\n",
    "                 'n_fold':r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "T4qTBvzB2Yhi",
   "metadata": {
    "id": "T4qTBvzB2Yhi"
   },
   "outputs": [],
   "source": [
    "class Trainer2(MLFlowBase):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"[FR] [Paris] [nhuberde] bitcoin project\",\n",
    "            \"https://mlflow.lewagon.co\")\n",
    "            \n",
    "    # def train(self, trainer_params, hyper_params):\n",
    "    def train(self, trainer_params, data):\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        # step 1 : iterate on trainer params\n",
    "        for param_combination in product(*trainer_params.values()):\n",
    "\n",
    "            exp_params = dict(zip(trainer_params.keys(), param_combination))\n",
    "\n",
    "            # print(exp_params)\n",
    "\n",
    "            # step 2 : iterate on models\n",
    "            # for model_name, model_hparams in hyper_params.items():\n",
    "\n",
    "                # print(f\"model name {model_name}\")\n",
    "\n",
    "                # step 3 : iterate on model hyperparams\n",
    "                # for hparam_combi in product(*model_hparams.values()):\n",
    "\n",
    "                #     hexp_params = dict(zip(model_hparams.keys(), hparam_combi))\n",
    "\n",
    "                    # print(hexp_params)\n",
    "\n",
    "                    # mais avec quoi je train ?\n",
    "            i += 1\n",
    "            print(f\"\\nexperiment #{i}:\")\n",
    "            print(exp_params)\n",
    "            # print(f\"model name {model_name}\")\n",
    "            # print(hexp_params)\n",
    "\n",
    "            # TODO: train with trainer params + model + hyperparams\n",
    "\n",
    "            # => appeler la crossval\n",
    "            # data = get_data()\n",
    "            results = deep(data, **exp_params)\n",
    "\n",
    "\n",
    "            # create a mlflow training\n",
    "            self.mlflow_create_run()  # create one training\n",
    "\n",
    "            # log trainer params\n",
    "            for key, value in exp_params.items():\n",
    "                self.mlflow_log_param(key, value)\n",
    "                \n",
    "            # then log buddy_name on mlflow\n",
    "            self.mlflow_log_param(\"buddy_name\", {buddy_name})\n",
    "            self.mlflow_log_param(\"model_type\", \"GRU\")\n",
    "\n",
    "            # log params\n",
    "            # self.mlflow_log_param(\"model\", model_name)\n",
    "\n",
    "            # log model hyper params\n",
    "            # for key, value in hexp_params.items():\n",
    "            #     self.mlflow_log_param(key, value)\n",
    "\n",
    "            # push metrics to mlflow\n",
    "            self.mlflow_log_metric(\"mean_score\", results['mean_score'])\n",
    "            self.mlflow_log_metric(\"std\", results['std'])\n",
    "            self.mlflow_log_metric(\"score_min\", results['score_min'])\n",
    "            self.mlflow_log_metric(\"score_max\", results['score_max'])\n",
    "            self.mlflow_log_metric(\"n_fold\", results['n_fold'])\n",
    "            \n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "Jl__fA0q4Cce",
   "metadata": {
    "id": "Jl__fA0q4Cce"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Eg9mNnhW0LI8",
   "metadata": {
    "id": "Eg9mNnhW0LI8"
   },
   "outputs": [],
   "source": [
    "results = deep(data, sample_size=1440, train_fraction=0.7, features_size=60, h=1, date_start=\"2020-10-01\", date_end=\"2020-10-07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "lHsIZuXR0LMW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHsIZuXR0LMW",
    "outputId": "746e6f36-8f69-416f-969c-40e55af90e85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_score': 0.51,\n",
       " 'n_fold': 20,\n",
       " 'score_max': 0.61,\n",
       " 'score_min': 0.47,\n",
       " 'std': 0.03}"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "jjSi59gH0LO6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjSi59gH0LO6",
    "outputId": "bfb9606f-db05-4c17-9033-3190e619792a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "experiment #1:\n",
      "{'sample_size': 1440, 'train_fraction': 0.7, 'features_size': 60, 'h': 1, 'date_start': '2020-10-01', 'date_end': '2020-10-07'}\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 78ms/step - loss: 0.6929 - accuracy: 0.5298 - val_loss: 0.6968 - val_accuracy: 0.4752\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6888 - accuracy: 0.5559 - val_loss: 0.6966 - val_accuracy: 0.4752\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6893 - accuracy: 0.5562 - val_loss: 0.6973 - val_accuracy: 0.4752\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 82ms/step - loss: 0.7268 - accuracy: 0.4835 - val_loss: 0.6942 - val_accuracy: 0.4802\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6965 - accuracy: 0.4991 - val_loss: 0.6936 - val_accuracy: 0.4802\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6944 - accuracy: 0.4971 - val_loss: 0.6937 - val_accuracy: 0.4802\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 79ms/step - loss: 0.7005 - accuracy: 0.4973 - val_loss: 0.6921 - val_accuracy: 0.5297\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6933 - accuracy: 0.5071 - val_loss: 0.6932 - val_accuracy: 0.4713\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6940 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5248\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 80ms/step - loss: 0.7514 - accuracy: 0.5059 - val_loss: 0.6996 - val_accuracy: 0.4802\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.7019 - accuracy: 0.4963 - val_loss: 0.6989 - val_accuracy: 0.4802\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6997 - accuracy: 0.4855 - val_loss: 0.6947 - val_accuracy: 0.4802\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 81ms/step - loss: 0.7296 - accuracy: 0.4828 - val_loss: 0.7115 - val_accuracy: 0.4356\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6998 - accuracy: 0.5055 - val_loss: 0.6970 - val_accuracy: 0.4356\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6964 - accuracy: 0.5015 - val_loss: 0.6991 - val_accuracy: 0.4356\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 79ms/step - loss: 0.7000 - accuracy: 0.5219 - val_loss: 0.6924 - val_accuracy: 0.5248\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6933 - accuracy: 0.5236 - val_loss: 0.6926 - val_accuracy: 0.5239\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6942 - accuracy: 0.5061 - val_loss: 0.6929 - val_accuracy: 0.5198\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 84ms/step - loss: 0.7041 - accuracy: 0.4989 - val_loss: 0.6991 - val_accuracy: 0.4554\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6960 - accuracy: 0.5041 - val_loss: 0.6973 - val_accuracy: 0.4554\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6931 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5446\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 81ms/step - loss: 0.6935 - accuracy: 0.5253 - val_loss: 0.6932 - val_accuracy: 0.4901\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6935 - accuracy: 0.5062 - val_loss: 0.6932 - val_accuracy: 0.4901\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.6933 - accuracy: 0.4739 - val_loss: 0.6932 - val_accuracy: 0.4901\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 87ms/step - loss: 0.6968 - accuracy: 0.4980 - val_loss: 0.6933 - val_accuracy: 0.4356\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6942 - accuracy: 0.4891 - val_loss: 0.6934 - val_accuracy: 0.4356\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6935 - accuracy: 0.5108 - val_loss: 0.6934 - val_accuracy: 0.4356\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 83ms/step - loss: 0.6959 - accuracy: 0.5169 - val_loss: 0.6903 - val_accuracy: 0.5446\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6903 - accuracy: 0.5500 - val_loss: 0.6907 - val_accuracy: 0.5446\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6929 - accuracy: 0.5303 - val_loss: 0.6909 - val_accuracy: 0.5446\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 82ms/step - loss: 0.7047 - accuracy: 0.4983 - val_loss: 0.6915 - val_accuracy: 0.5297\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6903 - accuracy: 0.5476 - val_loss: 0.6933 - val_accuracy: 0.4812\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6938 - accuracy: 0.5179 - val_loss: 0.6931 - val_accuracy: 0.5297\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 94ms/step - loss: 0.7463 - accuracy: 0.4657 - val_loss: 0.6841 - val_accuracy: 0.5670\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7046 - accuracy: 0.5046 - val_loss: 0.6936 - val_accuracy: 0.5416\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7042 - accuracy: 0.4950 - val_loss: 0.6848 - val_accuracy: 0.5693\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 75ms/step - loss: 0.6970 - accuracy: 0.5052 - val_loss: 0.7006 - val_accuracy: 0.4802\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6922 - accuracy: 0.5375 - val_loss: 0.6980 - val_accuracy: 0.4802\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6895 - accuracy: 0.5507 - val_loss: 0.6972 - val_accuracy: 0.4802\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 84ms/step - loss: 0.7165 - accuracy: 0.4922 - val_loss: 0.7077 - val_accuracy: 0.4901\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.7018 - accuracy: 0.5193 - val_loss: 0.6981 - val_accuracy: 0.4901\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6973 - accuracy: 0.5123 - val_loss: 0.6947 - val_accuracy: 0.4901\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 84ms/step - loss: 0.7203 - accuracy: 0.4768 - val_loss: 0.6980 - val_accuracy: 0.4554\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6979 - accuracy: 0.4822 - val_loss: 0.6922 - val_accuracy: 0.5446\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6936 - accuracy: 0.5094 - val_loss: 0.6921 - val_accuracy: 0.5446\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 87ms/step - loss: 0.7005 - accuracy: 0.5269 - val_loss: 0.6834 - val_accuracy: 0.5941\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.7048 - accuracy: 0.5011 - val_loss: 0.6843 - val_accuracy: 0.5941\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6983 - accuracy: 0.5135 - val_loss: 0.6859 - val_accuracy: 0.5941\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 82ms/step - loss: 0.6968 - accuracy: 0.5426 - val_loss: 0.6901 - val_accuracy: 0.5396\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6885 - accuracy: 0.5568 - val_loss: 0.6904 - val_accuracy: 0.5396\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6879 - accuracy: 0.5558 - val_loss: 0.6905 - val_accuracy: 0.5396\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 85ms/step - loss: 0.6928 - accuracy: 0.5365 - val_loss: 0.6934 - val_accuracy: 0.5050\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6940 - accuracy: 0.5130 - val_loss: 0.6934 - val_accuracy: 0.5050\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6893 - accuracy: 0.5586 - val_loss: 0.6935 - val_accuracy: 0.5050\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 78ms/step - loss: 0.7075 - accuracy: 0.5106 - val_loss: 0.6958 - val_accuracy: 0.5050\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.7013 - accuracy: 0.5034 - val_loss: 0.6933 - val_accuracy: 0.4967\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6979 - accuracy: 0.5019 - val_loss: 0.6933 - val_accuracy: 0.4965\n",
      "Epoch 1/3\n",
      "26/26 [==============================] - 6s 81ms/step - loss: 0.6941 - accuracy: 0.4864 - val_loss: 0.6930 - val_accuracy: 0.5198\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6933 - accuracy: 0.4939 - val_loss: 0.6928 - val_accuracy: 0.5198\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6927 - accuracy: 0.5267 - val_loss: 0.6929 - val_accuracy: 0.5198\n"
     ]
    }
   ],
   "source": [
    "trainer_params2 = dict(\n",
    "    sample_size=[1440],\n",
    "    train_fraction=[0.7],\n",
    "    features_size=[60],\n",
    "    h=[1],\n",
    "    date_start=[\"2020-10-01\"],\n",
    "    date_end=[\"2020-10-07\"],\n",
    ")\n",
    "\n",
    "trainer2 = Trainer2()\n",
    "trainer2.train(trainer_params2, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "PFOnRz3T9gX9",
   "metadata": {
    "id": "PFOnRz3T9gX9"
   },
   "outputs": [],
   "source": [
    "# data2 = select_date(data, date_start=None, date_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cftLHVz_0LR2",
   "metadata": {
    "id": "cftLHVz_0LR2"
   },
   "outputs": [],
   "source": [
    "# data_shifted = preprocessing_data(data2, features_size=120, h=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3Z2Apiir0LYh",
   "metadata": {
    "id": "3Z2Apiir0LYh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
