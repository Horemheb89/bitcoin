{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "previous-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demographic-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Flatten, Dense, SimpleRNN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-latin",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "appreciated-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../raw_data/bitstampUSD.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-burner",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "civic-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "buried-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"Timestamp\", \"Open\"]].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "figured-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_diff_col(data):\n",
    "    data['Open_diff'] = data[\"Open\"].diff()\n",
    "    clean_data = data[1:]\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fifteen-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = open_diff_col(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "negative-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = cleaned_data[2798176:]\n",
    "data_test = data_sample[1829602:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nuclear-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_encoding(data):\n",
    "    data['Coded'] = data['Open_diff'].map(lambda x: 0 if x <= 0 else 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conventional-parts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0e0d2571e76e>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Coded'] = data['Open_diff'].map(lambda x: 0 if x <= 0 else 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>Open_diff</th>\n",
       "      <th>Coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4627779</th>\n",
       "      <td>2020-10-22 13:23:00</td>\n",
       "      <td>12955.46</td>\n",
       "      <td>14.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627780</th>\n",
       "      <td>2020-10-22 13:24:00</td>\n",
       "      <td>12959.98</td>\n",
       "      <td>4.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627781</th>\n",
       "      <td>2020-10-22 13:25:00</td>\n",
       "      <td>12959.01</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627782</th>\n",
       "      <td>2020-10-22 13:26:00</td>\n",
       "      <td>12949.05</td>\n",
       "      <td>-9.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627783</th>\n",
       "      <td>2020-10-22 13:27:00</td>\n",
       "      <td>12952.39</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp      Open  Open_diff  Coded\n",
       "4627779 2020-10-22 13:23:00  12955.46      14.34      1\n",
       "4627780 2020-10-22 13:24:00  12959.98       4.52      1\n",
       "4627781 2020-10-22 13:25:00  12959.01      -0.97      0\n",
       "4627782 2020-10-22 13:26:00  12949.05      -9.96      0\n",
       "4627783 2020-10-22 13:27:00  12952.39       3.34      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded = y_encoding(data_test)\n",
    "y_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-humidity",
   "metadata": {},
   "source": [
    "# Dumb baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "included-pocket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0e0d2571e76e>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Coded'] = data['Open_diff'].map(lambda x: 0 if x <= 0 else 1)\n"
     ]
    }
   ],
   "source": [
    "baseline_sample = data_sample[:1000000]\n",
    "y_base = y_encoding(baseline_sample)\n",
    "base = y_base[['Coded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "radio-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.6\n",
    "index = round(train_size*base.shape[0])\n",
    "df_train = base.iloc[:index]\n",
    "df_test = base.iloc[index+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "experienced-flesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.49721748608743044\n"
     ]
    }
   ],
   "source": [
    "y_pred = df_test.shift(1).dropna()\n",
    "y_true = df_test[1:]\n",
    "print(f\"Accuracy:{accuracy_score(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-delta",
   "metadata": {},
   "source": [
    "# Simple Ridge Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "broadband-atlanta",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "upper-rachel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>Open_diff</th>\n",
       "      <th>Coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2798177</th>\n",
       "      <td>2017-05-01 00:01:00</td>\n",
       "      <td>1352.41</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798178</th>\n",
       "      <td>2017-05-01 00:02:00</td>\n",
       "      <td>1349.49</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798179</th>\n",
       "      <td>2017-05-01 00:03:00</td>\n",
       "      <td>1350.11</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798180</th>\n",
       "      <td>2017-05-01 00:04:00</td>\n",
       "      <td>1351.25</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798181</th>\n",
       "      <td>2017-05-01 00:05:00</td>\n",
       "      <td>1351.24</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp     Open  Open_diff  Coded\n",
       "2798177 2017-05-01 00:01:00  1352.41       3.53      1\n",
       "2798178 2017-05-01 00:02:00  1349.49      -2.92      0\n",
       "2798179 2017-05-01 00:03:00  1350.11       0.62      1\n",
       "2798180 2017-05-01 00:04:00  1351.25       1.14      1\n",
       "2798181 2017-05-01 00:05:00  1351.24      -0.01      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "enabling-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(data, sample_size, shift_size, train_size):\n",
    "\n",
    "    data_size = data.shape[0]\n",
    "    sample = data.iloc[(data_size-sample_size):data_size]\n",
    "    sample_pp = sample[['Open_diff', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "\n",
    "\n",
    "    for i in range(1, shift_size+1):\n",
    "        sample_pp[f't - {i}'] = sample_pp['Open_diff'].shift(i)\n",
    "    sample_shifted = sample_pp.dropna() \n",
    "\n",
    "\n",
    "    X = sample_shifted.drop(columns=['Open_diff'])\n",
    "    y = sample_shifted['Open_diff']\n",
    "\n",
    "\n",
    "    X_train = X.iloc[0:train_size]\n",
    "    y_train = y.iloc[0:train_size]\n",
    "    X_test = X.iloc[(train_size+1):(sample_size-shift_size)]\n",
    "    y_test = y.iloc[(train_size+1):(sample_size-shift_size)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "foreign-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = input_data(y_base, 10000, 20, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hundred-malawi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp\n",
       "2019-03-23 16:22:00    1.17\n",
       "2019-03-23 16:23:00    0.00\n",
       "2019-03-23 16:24:00    0.00\n",
       "2019-03-23 16:25:00    0.40\n",
       "2019-03-23 16:26:00    0.00\n",
       "2019-03-23 16:27:00   -0.40\n",
       "2019-03-23 16:28:00   -2.87\n",
       "2019-03-23 16:29:00    0.00\n",
       "2019-03-23 16:30:00    0.40\n",
       "2019-03-23 16:31:00   -0.92\n",
       "2019-03-23 16:32:00   -0.49\n",
       "2019-03-23 16:33:00    0.35\n",
       "2019-03-23 16:34:00    0.00\n",
       "2019-03-23 16:35:00   -0.35\n",
       "2019-03-23 16:36:00    0.24\n",
       "2019-03-23 16:37:00    0.04\n",
       "2019-03-23 16:38:00    0.00\n",
       "2019-03-23 16:39:00    0.71\n",
       "2019-03-23 16:40:00    0.00\n",
       "2019-03-23 16:41:00    0.00\n",
       "Name: Open_diff, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "annoying-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train > 0] = 1\n",
    "y_train[y_train <= 0] = 0\n",
    "y_test[y_test > 0] =1\n",
    "y_test[y_test <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "interior-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_classifier(X_train, X_test, y_train, y_test):\n",
    "    log_reg = RidgeClassifier()\n",
    "    log_reg = log_reg.fit(X_train, y_train)\n",
    "    results = log_reg.predict(X_test)\n",
    "    score = log_reg.score(X_test, y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "utility-stupid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6154812767026892"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-while",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "vietnamese-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf = rf.fit(X_train, y_train)\n",
    "result = rf.predict(X_test)\n",
    "result[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "advance-sandwich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6054284996230208"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_score = rf.score(X_test, y_test)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-thesaurus",
   "metadata": {},
   "source": [
    "### with cross-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "existing-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(RandomForestClassifier(), X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tested-humidity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58833333, 0.545     , 0.54333333, 0.585     , 0.49166667,\n",
       "       0.57833333, 0.58      , 0.51333333, 0.60833333, 0.52      ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_array = cv_results['test_score']\n",
    "cv_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "classified-documentary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5553333333333332"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_accuracy = cv_array.mean()\n",
    "cv_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-baker",
   "metadata": {},
   "source": [
    "## Functions for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ignored-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data, shift_size, h=1):\n",
    "    data_pp = data[2798176:4727776]\n",
    "    data_pp['Timestamp'] = pd.to_datetime(data_pp['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data_pp[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data_pp['diff_Open'] = data_pp['Open'].diff(h)\n",
    "    data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    data_pp[f\"t+{h}\"] = data_pp['diff_Open'].shift(-h)\n",
    "    for i in range(0, shift_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna()\n",
    "    X = data_shifted.drop(columns=['Open', 'diff_Open', f\"t+{h}\"])\n",
    "    y = data_shifted[f\"t+{h}\"].copy()\n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    return X, y, data_shifted\n",
    "\n",
    "def input_data(data, sample_size, shift_size, train_size, h=1, w=0):\n",
    "    X, y, data_shifted = preprocessing_data(data, shift_size, h)\n",
    "    data_size = data_shifted.shape[0]\n",
    "    sample_X = X.iloc[(data_size-sample_size-w):data_size-w]\n",
    "    sample_y = y.iloc[(data_size-sample_size-w):data_size-w]\n",
    "    X_train = sample_X.iloc[0:train_size]\n",
    "    y_train = sample_y.iloc[0:train_size]\n",
    "    X_test = sample_X.iloc[(train_size+h-1):(sample_size-shift_size)]\n",
    "    y_test = sample_y.iloc[(train_size+h-1):(sample_size-shift_size)]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "compliant-summer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-144caf4e93e5>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pp['Timestamp'] = pd.to_datetime(data_pp['Timestamp'], unit='s', origin='unix')\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = input_data(data, 3000, 5, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "elementary-polls",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 5), (2000,), (995, 5), (995,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-airline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_reshape(X_train, X_test, y_train, y_test):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-gasoline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "changing-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_retrain, y_retrain = np.array(X_train), np.array(y_train)\n",
    "X_retrain = np.reshape(X_retrain, (X_retrain.shape[0], X_retrain.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "imposed-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_retest, y_retest = np.array(X_test), np.array(y_test)\n",
    "X_retest = np.reshape(X_retest, (X_retest.shape[0], X_retest.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-qatar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.SimpleRNN(units=10, activation='tanh'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "history = model.fit(X_retrain, y_retrain,\n",
    "#                     validation_split=0.3,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_retest, y_retest, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-desktop",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-intent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-plaza",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "european-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.SimpleRNN(units=10, activation='tanh'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "simplified-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "junior-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "motivated-customs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 1.0429 - accuracy: 0.5035\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.8473 - accuracy: 0.4986\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.5099\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.4963\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4913\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5019\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4962\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4995\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4833\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5021\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5195\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4827\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4969\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5104\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4888\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5008\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4799\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4740\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4990\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5054\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4885\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4850\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4820\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5192\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4887\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4721\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5124\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4917\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4689\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5023\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4761\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5164\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5015\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4755\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4926\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5012\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5129\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4902\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4913\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5211\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5119\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4919\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4739\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5013\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4664\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4991\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5019\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4989\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4977\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4984\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "history = model.fit(X_retrain, y_retrain,\n",
    "#                     validation_split=0.3,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "hundred-sussex",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.6930 - accuracy: 0.5226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6930075883865356, 0.5226130485534668]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_retest, y_retest, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-jaguar",
   "metadata": {},
   "source": [
    "## basic RNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "significant-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (data, 12000, 10, 8000, h=1, w=0)\n",
    "# units=10, Dense 5, Dense 1\n",
    "# loss: 0.6931475400924683, accuracy: 0.49724310636520386]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-butterfly",
   "metadata": {},
   "source": [
    "# More advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-bonus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-tradition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(layers.SimpleRNN(units=1, activation='tanh'))\n",
    "# model.add(layers.Dense(1, activation=\"relu\"))\n",
    "\n",
    "# # The compilation\n",
    "# model.compile(loss='binary_crossentropy', \n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # The fit\n",
    "# model.fit(X_train, y_train,\n",
    "#             validation_split=0.2,\n",
    "#          batch_size=16,\n",
    "#          epochs=5, verbose=0)\n",
    "\n",
    "# # The prediction\n",
    "# model.predict(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_model = Sequential()\n",
    "# lstm_model.add(layers.Masking(mask_value=-1000))\n",
    "# lstm_model.add(layers.LSTM(units=10, activation='tanh')) \n",
    "# lstm_model.add(layers.Dense(20, activation=\"tanh\"))\n",
    "# lstm_model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# lstm_model.compile(loss='categorical_crossentropy', \n",
    "#               optimizer='rmsprop',\n",
    "#               metrics = 'accuracy')\n",
    "\n",
    "# es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "# lstm_history = lstm_model.fit(X_train, y_train,\n",
    "#           validation_split = 0.2,\n",
    "#           batch_size=16,\n",
    "#           callbacks=[es],\n",
    "#           epochs=50)\n",
    "\n",
    "# lstm_model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU_model = Sequential()\n",
    "# GRU_model.add(layers.Masking(mask_value=-1000))\n",
    "# GRU_model.add(layers.GRU(units=10, activation='tanh')) \n",
    "# GRU_model.add(layers.Dense(20, activation=\"tanh\"))\n",
    "# GRU_model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# GRU_model.compile(loss='categorical_crossentropy', \n",
    "#               optimizer='rmsprop',\n",
    "#               metrics = 'accuracy')\n",
    "\n",
    "# es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "# GRU_history = lstm_model.fit(X_train, y_train,\n",
    "#           validation_split = 0.2,\n",
    "#           batch_size=16,\n",
    "#           callbacks=[es],\n",
    "#           epochs=50)\n",
    "\n",
    "# GRU_model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-intellectual",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-oxygen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-aurora",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-authentication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-variety",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-musician",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
