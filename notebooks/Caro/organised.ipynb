{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "previous-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demographic-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Flatten, Dense, SimpleRNN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-latin",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "appreciated-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../raw_data/bitstampUSD.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-burner",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "civic-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "buried-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"Timestamp\", \"Open\"]].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "figured-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_diff_col(data):\n",
    "    data['Open_diff'] = data[\"Open\"].diff()\n",
    "    clean_data = data[1:]\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fifteen-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = open_diff_col(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "negative-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = cleaned_data[2798176:]\n",
    "data_test = data_sample[1829602:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nuclear-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_encoding(data):\n",
    "    data['Coded'] = data['Open_diff'].map(lambda x: 0 if x <= 0 else 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conventional-parts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0e0d2571e76e>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Coded'] = data['Open_diff'].map(lambda x: 0 if x <= 0 else 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>Open_diff</th>\n",
       "      <th>Coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4627779</th>\n",
       "      <td>2020-10-22 13:23:00</td>\n",
       "      <td>12955.46</td>\n",
       "      <td>14.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627780</th>\n",
       "      <td>2020-10-22 13:24:00</td>\n",
       "      <td>12959.98</td>\n",
       "      <td>4.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627781</th>\n",
       "      <td>2020-10-22 13:25:00</td>\n",
       "      <td>12959.01</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627782</th>\n",
       "      <td>2020-10-22 13:26:00</td>\n",
       "      <td>12949.05</td>\n",
       "      <td>-9.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627783</th>\n",
       "      <td>2020-10-22 13:27:00</td>\n",
       "      <td>12952.39</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp      Open  Open_diff  Coded\n",
       "4627779 2020-10-22 13:23:00  12955.46      14.34      1\n",
       "4627780 2020-10-22 13:24:00  12959.98       4.52      1\n",
       "4627781 2020-10-22 13:25:00  12959.01      -0.97      0\n",
       "4627782 2020-10-22 13:26:00  12949.05      -9.96      0\n",
       "4627783 2020-10-22 13:27:00  12952.39       3.34      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded = y_encoding(data_test)\n",
    "y_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-humidity",
   "metadata": {},
   "source": [
    "# Dumb baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "included-pocket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0e0d2571e76e>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Coded'] = data['Open_diff'].map(lambda x: 0 if x <= 0 else 1)\n"
     ]
    }
   ],
   "source": [
    "baseline_sample = data_sample[:1000000]\n",
    "y_base = y_encoding(baseline_sample)\n",
    "base = y_base[['Coded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "radio-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.6\n",
    "index = round(train_size*base.shape[0])\n",
    "df_train = base.iloc[:index]\n",
    "df_test = base.iloc[index+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "experienced-flesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.49721748608743044\n"
     ]
    }
   ],
   "source": [
    "y_pred = df_test.shift(1).dropna()\n",
    "y_true = df_test[1:]\n",
    "print(f\"Accuracy:{accuracy_score(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-delta",
   "metadata": {},
   "source": [
    "# Simple Ridge Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "broadband-atlanta",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "upper-rachel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>Open_diff</th>\n",
       "      <th>Coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2798177</th>\n",
       "      <td>2017-05-01 00:01:00</td>\n",
       "      <td>1352.41</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798178</th>\n",
       "      <td>2017-05-01 00:02:00</td>\n",
       "      <td>1349.49</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798179</th>\n",
       "      <td>2017-05-01 00:03:00</td>\n",
       "      <td>1350.11</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798180</th>\n",
       "      <td>2017-05-01 00:04:00</td>\n",
       "      <td>1351.25</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798181</th>\n",
       "      <td>2017-05-01 00:05:00</td>\n",
       "      <td>1351.24</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp     Open  Open_diff  Coded\n",
       "2798177 2017-05-01 00:01:00  1352.41       3.53      1\n",
       "2798178 2017-05-01 00:02:00  1349.49      -2.92      0\n",
       "2798179 2017-05-01 00:03:00  1350.11       0.62      1\n",
       "2798180 2017-05-01 00:04:00  1351.25       1.14      1\n",
       "2798181 2017-05-01 00:05:00  1351.24      -0.01      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "enabling-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(data, sample_size, shift_size, train_size):\n",
    "\n",
    "    data_size = data.shape[0]\n",
    "    sample = data.iloc[(data_size-sample_size):data_size]\n",
    "    sample_pp = sample[['Open_diff', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "\n",
    "\n",
    "    for i in range(1, shift_size+1):\n",
    "        sample_pp[f't - {i}'] = sample_pp['Open_diff'].shift(i)\n",
    "    sample_shifted = sample_pp.dropna() \n",
    "\n",
    "\n",
    "    X = sample_shifted.drop(columns=['Open_diff'])\n",
    "    y = sample_shifted['Open_diff']\n",
    "\n",
    "\n",
    "    X_train = X.iloc[0:train_size]\n",
    "    y_train = y.iloc[0:train_size]\n",
    "    X_test = X.iloc[(train_size+1):(sample_size-shift_size)]\n",
    "    y_test = y.iloc[(train_size+1):(sample_size-shift_size)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "foreign-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = input_data(y_base, 10000, 20, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hundred-malawi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp\n",
       "2019-03-23 16:22:00    1.17\n",
       "2019-03-23 16:23:00    0.00\n",
       "2019-03-23 16:24:00    0.00\n",
       "2019-03-23 16:25:00    0.40\n",
       "2019-03-23 16:26:00    0.00\n",
       "2019-03-23 16:27:00   -0.40\n",
       "2019-03-23 16:28:00   -2.87\n",
       "2019-03-23 16:29:00    0.00\n",
       "2019-03-23 16:30:00    0.40\n",
       "2019-03-23 16:31:00   -0.92\n",
       "2019-03-23 16:32:00   -0.49\n",
       "2019-03-23 16:33:00    0.35\n",
       "2019-03-23 16:34:00    0.00\n",
       "2019-03-23 16:35:00   -0.35\n",
       "2019-03-23 16:36:00    0.24\n",
       "2019-03-23 16:37:00    0.04\n",
       "2019-03-23 16:38:00    0.00\n",
       "2019-03-23 16:39:00    0.71\n",
       "2019-03-23 16:40:00    0.00\n",
       "2019-03-23 16:41:00    0.00\n",
       "Name: Open_diff, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "annoying-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train > 0] = 1\n",
    "y_train[y_train <= 0] = 0\n",
    "y_test[y_test > 0] =1\n",
    "y_test[y_test <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "interior-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_classifier(X_train, X_test, y_train, y_test):\n",
    "    log_reg = RidgeClassifier()\n",
    "    log_reg = log_reg.fit(X_train, y_train)\n",
    "    results = log_reg.predict(X_test)\n",
    "    score = log_reg.score(X_test, y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "utility-stupid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6154812767026892"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-while",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "vietnamese-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf = rf.fit(X_train, y_train)\n",
    "result = rf.predict(X_test)\n",
    "result[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "advance-sandwich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074390550389545"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_score = rf.score(X_test, y_test)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-thesaurus",
   "metadata": {},
   "source": [
    "### with cross-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "existing-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(RandomForestClassifier(), X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tested-humidity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58166667, 0.545     , 0.545     , 0.57666667, 0.47333333,\n",
       "       0.58      , 0.58833333, 0.545     , 0.60333333, 0.55666667])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_array = cv_results['test_score']\n",
    "cv_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "classified-documentary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5595"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_accuracy = cv_array.mean()\n",
    "cv_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-baker",
   "metadata": {},
   "source": [
    "## Functions for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ignored-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data, shift_size, h=1):\n",
    "    data_pp = data[2798176:4727776]\n",
    "    data_pp['Timestamp'] = pd.to_datetime(data_pp['Timestamp'], unit='s', origin='unix')\n",
    "    data_pp = data_pp[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    data_pp['diff_Open'] = data_pp['Open'].diff(h)\n",
    "    data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    data_pp[f\"t+{h}\"] = data_pp['diff_Open'].shift(-h)\n",
    "    for i in range(0, shift_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna()\n",
    "    X = data_shifted.drop(columns=['Open', 'diff_Open', f\"t+{h}\"])\n",
    "    y = data_shifted[f\"t+{h}\"].copy()\n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    return X, y, data_shifted\n",
    "\n",
    "def input_data(data, sample_size, shift_size, train_size, h=1, w=0):\n",
    "    X, y, data_shifted = preprocessing_data(data, shift_size, h)\n",
    "    data_size = data_shifted.shape[0]\n",
    "    sample_X = X.iloc[(data_size-sample_size-w):data_size-w]\n",
    "    sample_y = y.iloc[(data_size-sample_size-w):data_size-w]\n",
    "    X_train = sample_X.iloc[0:train_size]\n",
    "    y_train = sample_y.iloc[0:train_size]\n",
    "    X_test = sample_X.iloc[(train_size+h-1):(sample_size-shift_size)]\n",
    "    y_test = sample_y.iloc[(train_size+h-1):(sample_size-shift_size)]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "compliant-summer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-144caf4e93e5>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pp['Timestamp'] = pd.to_datetime(data_pp['Timestamp'], unit='s', origin='unix')\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = input_data(data, 30000, 10, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "elementary-polls",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 10), (20000,), (9990, 10), (9990,))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-airline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "shared-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_reshape(X_train, X_test, y_train, y_test):\n",
    "    X_retrain, y_retrain = np.array(X_train), np.array(y_train)\n",
    "    X_retrain = np.reshape(X_retrain, (X_retrain.shape[0], X_retrain.shape[1], 1))\n",
    "    X_retest, y_retest = np.array(X_test), np.array(y_test)\n",
    "    X_retest = np.reshape(X_retest, (X_retest.shape[0], X_retest.shape[1], 1))\n",
    "    return X_retrain, X_retest, y_retrain, y_retest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "english-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_retrain, X_retest, y_retrain, y_retest = deep_reshape(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "changing-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_retrain, y_retrain = np.array(X_train), np.array(y_train)\n",
    "# X_retrain = np.reshape(X_retrain, (X_retrain.shape[0], X_retrain.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "imposed-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_retest, y_retest = np.array(X_test), np.array(y_test)\n",
    "# X_retest = np.reshape(X_retest, (X_retest.shape[0], X_retest.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "european-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.SimpleRNN(units=10, activation='tanh'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "simplified-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "junior-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "motivated-customs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.8465 - accuracy: 0.4978\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7345 - accuracy: 0.4921\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4946\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4802\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4849\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4883\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5132\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4922\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5106\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4974\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4898\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5151\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4939\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5094\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5124\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4946\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5130\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5046\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4958\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4832\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4786\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4935\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4980\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5039\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4963\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4692\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4903\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5179\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4959\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4776\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5130\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5025\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4985\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4887\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4945\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4696\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4726\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4799\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4911\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4960\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4939\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5128\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5046\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4710\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4728\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5122\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4961\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4757\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5172\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "history = model.fit(X_retrain, y_retrain,\n",
    "#                     validation_split=0.3,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "hundred-sussex",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.6929 - accuracy: 0.5226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6928801536560059, 0.5226130485534668]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_retest, y_retest, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-jaguar",
   "metadata": {},
   "source": [
    "## basic RNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (data, 12000, 10, 8000, h=1, w=0)\n",
    "# units=10, Dense 5, Dense 1\n",
    "# loss: 0.6931475400924683, accuracy: 0.49724310636520386]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-butterfly",
   "metadata": {},
   "source": [
    "# More advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "popular-night",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.6935 - accuracy: 0.5009 - val_loss: 0.6948 - val_accuracy: 0.4940\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6924 - accuracy: 0.5151 - val_loss: 0.6934 - val_accuracy: 0.4940\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5097 - val_loss: 0.6931 - val_accuracy: 0.5060\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5062 - val_loss: 0.6935 - val_accuracy: 0.4940\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6934 - accuracy: 0.4908 - val_loss: 0.6934 - val_accuracy: 0.4940\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6937 - val_accuracy: 0.4940\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5066 - val_loss: 0.6931 - val_accuracy: 0.5060\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5102 - val_loss: 0.6931 - val_accuracy: 0.5060\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6933 - accuracy: 0.5024 - val_loss: 0.6936 - val_accuracy: 0.4940\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6934 - accuracy: 0.4996 - val_loss: 0.6939 - val_accuracy: 0.4940\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6929 - accuracy: 0.5072 - val_loss: 0.6937 - val_accuracy: 0.4940\n",
      "313/313 - 1s - loss: 0.6932 - accuracy: 0.4927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931760311126709, 0.4926926791667938]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(layers.LSTM(units=10, activation='tanh')) \n",
    "lstm_model.add(layers.Dense(5, activation=\"tanh\"))\n",
    "lstm_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop',\n",
    "              metrics = 'accuracy')\n",
    "\n",
    "es = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "lstm_history = lstm_model.fit(X_retrain, y_retrain,\n",
    "          validation_split = 0.2,\n",
    "          batch_size=16,\n",
    "          callbacks=[es],\n",
    "          epochs=50)\n",
    "\n",
    "lstm_model.evaluate(X_retest, y_retest, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "olive-knight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5069 - val_loss: 0.6935 - val_accuracy: 0.4940\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6933 - accuracy: 0.5071 - val_loss: 0.6936 - val_accuracy: 0.4940\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5079 - val_loss: 0.6935 - val_accuracy: 0.4940\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4940\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6932 - val_accuracy: 0.4940\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5034 - val_loss: 0.6938 - val_accuracy: 0.4940\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6933 - accuracy: 0.5027 - val_loss: 0.6936 - val_accuracy: 0.4940\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6933 - accuracy: 0.5064 - val_loss: 0.6937 - val_accuracy: 0.4940\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6932 - val_accuracy: 0.4940\n",
      "313/313 - 1s - loss: 0.6932 - accuracy: 0.5073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6932079792022705, 0.5073072910308838]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRU_model = Sequential()\n",
    "GRU_model.add(layers.GRU(units=10, activation='tanh')) \n",
    "GRU_model.add(layers.Dense(20, activation=\"tanh\"))\n",
    "GRU_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "GRU_model.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop',\n",
    "              metrics = 'accuracy')\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "GRU_history = lstm_model.fit(X_retrain, y_retrain,\n",
    "          validation_split = 0.2,\n",
    "          batch_size=16,\n",
    "          callbacks=[es],\n",
    "          epochs=50)\n",
    "\n",
    "GRU_model.evaluate(X_retest, y_retest, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-intellectual",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-oxygen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-aurora",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-authentication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-variety",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-musician",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
